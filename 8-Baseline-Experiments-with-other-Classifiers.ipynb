{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Baseline Experiments with other Classifiers"]},{"cell_type":"markdown","metadata":{},"source":["For the paper, I performed additional experiments to analyze the default scores, obtained with the dummy classifier and SVMs."]},{"cell_type":"markdown","metadata":{},"source":["## Preparing the dataset"]},{"cell_type":"markdown","metadata":{},"source":["Importing the necessary libraries"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2022-02-11T10:14:19.885851Z","iopub.status.busy":"2022-02-11T10:14:19.885492Z","iopub.status.idle":"2022-02-11T10:14:19.915615Z","shell.execute_reply":"2022-02-11T10:14:19.914828Z","shell.execute_reply.started":"2022-02-11T10:14:19.885763Z"},"trusted":true},"outputs":[],"source":["import json\n","import pandas as pd\n","#from copy import deepcopy\n","import re\n","#from tqdm import tqdm\n","import numpy as np\n","import pandas as pd\n","import sklearn.model_selection\n","from sklearn import metrics\n","from sklearn.metrics import classification_report, f1_score\n","from sklearn.dummy import DummyClassifier\n","from sklearn.pipeline import make_pipeline\n","from sklearn.naive_bayes import MultinomialNB,ComplementNB\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.svm import SVC\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.metrics import ConfusionMatrixDisplay\n","import matplotlib.pyplot as plt\n","import sklearn.feature_extraction\n","from sklearn.svm import SVC"]},{"cell_type":"code","execution_count":49,"metadata":{"execution":{"iopub.execute_input":"2022-02-11T10:14:25.954732Z","iopub.status.busy":"2022-02-11T10:14:25.954116Z","iopub.status.idle":"2022-02-11T10:14:27.429913Z","shell.execute_reply":"2022-02-11T10:14:27.428735Z","shell.execute_reply.started":"2022-02-11T10:14:25.954693Z"},"executionInfo":{"elapsed":389,"status":"ok","timestamp":1640949108560,"user":{"displayName":"Taja Kuzman","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16199926972677634189"},"user_tz":-60},"id":"qL9iYqif_lSk","trusted":true},"outputs":[{"data":{"text/plain":["{'id': '3949',\n"," 'url': 'http://www.pomurje.si/aktualno/sport/zimska-liga-malega-nogometa/',\n"," 'crawled': '2014',\n"," 'hard': False,\n"," 'paragraphs': [],\n"," 'primary_level_1': 'News/Reporting',\n"," 'primary_level_2': 'News/Reporting',\n"," 'primary_level_3': 'News/Reporting',\n"," 'secondary_level_1': '',\n"," 'secondary_level_2': '',\n"," 'secondary_level_3': '',\n"," 'tertiary_level_1': '',\n"," 'tertiary_level_2': '',\n"," 'tertiary_level_3': '',\n"," 'split': 'test',\n"," 'domain': 'www.pomurje.si',\n"," 'baseline_text': \"Šport Zimska liga malega nogometa sobota, 12.02.2011 avtor: Tonček Gider V 7. krogu zimske lige v malem nogometu v Križevcih pri Ljutomeru je v prvi ligi vodilni 100 plus iz Križevec izgubil s tretjo ekipo na lestvici Rock'n roll iz Križevec z rezultatom 1:2, druga na lestvici Top Finedika iz Križevec je bila poražena z ekipo Bar Milene iz Ključarovec z rezultatom 7:8. V drugi križevski ligi je vodilni Cafe del Mar iz Vučje vasi premagal Montažo Vrbnjak iz Stare Nove vasi z rezultatom 3:2. oglasno sporočilo Ocena\",\n"," 'no_of_words': 88,\n"," 'lemmas': \"šport zimski liga mali nogomet sobota , 12.02.2011 avtor : Tonček Gider v 7. krog zimski liga v mali nogomet v Križevci pri Ljutomer biti v prvi liga vodilen 100 plus iz Križevci izgubiti z tretji ekipa na lestvica Rock'n roll iz Križevci z rezultat 1:2 , drug na lestvica Top Finedika iz Križevci biti biti poražen z ekipa Bar Milena iz Ključarovec z rezultat 7:8 . v drug križevski liga biti vodilen Cafe del mar iz Vučji vas premagati montaža Vrbnjak iz star nov vas z rezultat 3:2 . oglasen sporočilo ocena \",\n"," 'upos': 'NOUN ADJ NOUN ADJ NOUN NOUN PUNCT NUM NOUN PUNCT PROPN PROPN ADP NUM NOUN ADJ NOUN ADP ADJ NOUN ADP PROPN ADP PROPN AUX ADP ADJ NOUN ADJ NUM NOUN ADP PROPN VERB ADP ADJ NOUN ADP NOUN PROPN NOUN ADP PROPN ADP NOUN NUM PUNCT ADJ ADP NOUN PROPN PROPN ADP PROPN AUX AUX ADJ ADP NOUN PROPN PROPN ADP PROPN ADP NOUN NUM PUNCT ADP ADJ ADJ NOUN AUX ADJ PROPN NOUN ADV ADP ADJ NOUN VERB NOUN PROPN ADP ADJ ADJ NOUN ADP NOUN NUM PUNCT ADJ NOUN NOUN ',\n"," 'xpos': 'Ncmsn Agpfsn Ncfsn Agpmsg Ncmsg Ncfsn Z Mdc Ncmsn Z Npmsn Npmsn Sl Mdo Ncmsl Agpfsg Ncfsg Sl Agpmsl Ncmsl Sl Npmpl Sl Npmsl Va-r3s-n Sl Mlofsl Ncfsl Agpmsny Mdc Ncmsn Sg Npmpg Vmep-sm Si Mlofsi Ncfsi Sl Ncfsl Npmsn Ncmsn Sg Npmpg Si Ncmsi Mdc Z Mlpfsn Sl Ncfsl Npmsn Npfsn Sg Npmpg Va-r3s-n Va-p-sf Appfsn Si Ncfsi Npmsn Npfsg Sg Npmsg Si Ncmsi Mdc Z Sl Mlpfsl Agpfsl Ncfsl Va-r3s-n Agpmsny Npmsn Ncmsn Rgp Sg Agpfsg Ncfsg Vmep-sm Ncfsa Npmsn Sg Agpfsg Agpfsg Ncfsg Si Ncmsi Mdc Z Agpnsn Ncnsn Ncfsn ',\n"," 'ner': 'O B-MISC I-MISC I-MISC I-MISC I-MISC O O O O B-PER I-PER O O O O O O O O O B-LOC O B-LOC O O O O O O O O B-LOC O O O O O O B-ORG O O B-LOC O O O O O O O B-ORG I-ORG O B-LOC O O O O O B-ORG I-ORG O B-LOC O O O O O O O O O O B-ORG I-ORG I-ORG O B-LOC I-LOC O B-ORG I-ORG O B-LOC I-LOC I-LOC O O O O O O O ',\n"," 'dependency': 'parataxis amod nmod amod nmod nmod punct nummod conj punct nmod flat:name case nummod obl amod nmod case amod nmod case nmod case nmod aux case amod obl amod nummod nmod case nmod root case amod obl case nmod nmod nmod case nmod case nmod nummod punct nsubj case nmod nmod nmod case nmod aux cop parataxis case obl nmod nmod case nmod case nmod nummod punct case amod amod obl aux amod nmod nsubj advmod case amod obl root obj nmod case amod amod nmod case nmod nummod punct amod parataxis nmod ',\n"," 'lowercase': \"šport zimska liga malega nogometa sobota, 12.02.2011 avtor: tonček gider v 7. krogu zimske lige v malem nogometu v križevcih pri ljutomeru je v prvi ligi vodilni 100 plus iz križevec izgubil s tretjo ekipo na lestvici rock'n roll iz križevec z rezultatom 1:2, druga na lestvici top finedika iz križevec je bila poražena z ekipo bar milene iz ključarovec z rezultatom 7:8. v drugi križevski ligi je vodilni cafe del mar iz vučje vasi premagal montažo vrbnjak iz stare nove vasi z rezultatom 3:2. oglasno sporočilo ocena\",\n"," 'lowercase_nopunctuation': 'šport zimska liga malega nogometa sobota 12022011 avtor tonček gider v 7 krogu zimske lige v malem nogometu v križevcih pri ljutomeru je v prvi ligi vodilni 100 plus iz križevec izgubil s tretjo ekipo na lestvici rockn roll iz križevec z rezultatom 12 druga na lestvici top finedika iz križevec je bila poražena z ekipo bar milene iz ključarovec z rezultatom 78 v drugi križevski ligi je vodilni cafe del mar iz vučje vasi premagal montažo vrbnjak iz stare nove vasi z rezultatom 32 oglasno sporočilo ocena',\n"," 'representation_list': [['šport', 'NOUN', 'Ncmsn', 'O', 'parataxis'],\n","  ['zimski', 'ADJ', 'Agpfsn', 'B-MISC', 'amod'],\n","  ['liga', 'NOUN', 'Ncfsn', 'I-MISC', 'nmod'],\n","  ['mali', 'ADJ', 'Agpmsg', 'I-MISC', 'amod'],\n","  ['nogomet', 'NOUN', 'Ncmsg', 'I-MISC', 'nmod'],\n","  ['sobota', 'NOUN', 'Ncfsn', 'I-MISC', 'nmod'],\n","  [',', 'PUNCT', 'Z', 'O', 'punct'],\n","  ['12.02.2011', 'NUM', 'Mdc', 'O', 'nummod'],\n","  ['avtor', 'NOUN', 'Ncmsn', 'O', 'conj'],\n","  [':', 'PUNCT', 'Z', 'O', 'punct'],\n","  ['Tonček', 'PROPN', 'Npmsn', 'B-PER', 'nmod'],\n","  ['Gider', 'PROPN', 'Npmsn', 'I-PER', 'flat:name'],\n","  ['v', 'ADP', 'Sl', 'O', 'case'],\n","  ['7.', 'NUM', 'Mdo', 'O', 'nummod'],\n","  ['krog', 'NOUN', 'Ncmsl', 'O', 'obl'],\n","  ['zimski', 'ADJ', 'Agpfsg', 'O', 'amod'],\n","  ['liga', 'NOUN', 'Ncfsg', 'O', 'nmod'],\n","  ['v', 'ADP', 'Sl', 'O', 'case'],\n","  ['mali', 'ADJ', 'Agpmsl', 'O', 'amod'],\n","  ['nogomet', 'NOUN', 'Ncmsl', 'O', 'nmod'],\n","  ['v', 'ADP', 'Sl', 'O', 'case'],\n","  ['Križevci', 'PROPN', 'Npmpl', 'B-LOC', 'nmod'],\n","  ['pri', 'ADP', 'Sl', 'O', 'case'],\n","  ['Ljutomer', 'PROPN', 'Npmsl', 'B-LOC', 'nmod'],\n","  ['biti', 'AUX', 'Va-r3s-n', 'O', 'aux'],\n","  ['v', 'ADP', 'Sl', 'O', 'case'],\n","  ['prvi', 'ADJ', 'Mlofsl', 'O', 'amod'],\n","  ['liga', 'NOUN', 'Ncfsl', 'O', 'obl'],\n","  ['vodilen', 'ADJ', 'Agpmsny', 'O', 'amod'],\n","  ['100', 'NUM', 'Mdc', 'O', 'nummod'],\n","  ['plus', 'NOUN', 'Ncmsn', 'O', 'nmod'],\n","  ['iz', 'ADP', 'Sg', 'O', 'case'],\n","  ['Križevci', 'PROPN', 'Npmpg', 'B-LOC', 'nmod'],\n","  ['izgubiti', 'VERB', 'Vmep-sm', 'O', 'root'],\n","  ['z', 'ADP', 'Si', 'O', 'case'],\n","  ['tretji', 'ADJ', 'Mlofsi', 'O', 'amod'],\n","  ['ekipa', 'NOUN', 'Ncfsi', 'O', 'obl'],\n","  ['na', 'ADP', 'Sl', 'O', 'case'],\n","  ['lestvica', 'NOUN', 'Ncfsl', 'O', 'nmod'],\n","  [\"Rock'n\", 'PROPN', 'Npmsn', 'B-ORG', 'nmod'],\n","  ['roll', 'NOUN', 'Ncmsn', 'O', 'nmod'],\n","  ['iz', 'ADP', 'Sg', 'O', 'case'],\n","  ['Križevci', 'PROPN', 'Npmpg', 'B-LOC', 'nmod'],\n","  ['z', 'ADP', 'Si', 'O', 'case'],\n","  ['rezultat', 'NOUN', 'Ncmsi', 'O', 'nmod'],\n","  ['1:2', 'NUM', 'Mdc', 'O', 'nummod'],\n","  [',', 'PUNCT', 'Z', 'O', 'punct'],\n","  ['drug', 'ADJ', 'Mlpfsn', 'O', 'nsubj'],\n","  ['na', 'ADP', 'Sl', 'O', 'case'],\n","  ['lestvica', 'NOUN', 'Ncfsl', 'O', 'nmod'],\n","  ['Top', 'PROPN', 'Npmsn', 'B-ORG', 'nmod'],\n","  ['Finedika', 'PROPN', 'Npfsn', 'I-ORG', 'nmod'],\n","  ['iz', 'ADP', 'Sg', 'O', 'case'],\n","  ['Križevci', 'PROPN', 'Npmpg', 'B-LOC', 'nmod'],\n","  ['biti', 'AUX', 'Va-r3s-n', 'O', 'aux'],\n","  ['biti', 'AUX', 'Va-p-sf', 'O', 'cop'],\n","  ['poražen', 'ADJ', 'Appfsn', 'O', 'parataxis'],\n","  ['z', 'ADP', 'Si', 'O', 'case'],\n","  ['ekipa', 'NOUN', 'Ncfsi', 'O', 'obl'],\n","  ['Bar', 'PROPN', 'Npmsn', 'B-ORG', 'nmod'],\n","  ['Milena', 'PROPN', 'Npfsg', 'I-ORG', 'nmod'],\n","  ['iz', 'ADP', 'Sg', 'O', 'case'],\n","  ['Ključarovec', 'PROPN', 'Npmsg', 'B-LOC', 'nmod'],\n","  ['z', 'ADP', 'Si', 'O', 'case'],\n","  ['rezultat', 'NOUN', 'Ncmsi', 'O', 'nmod'],\n","  ['7:8', 'NUM', 'Mdc', 'O', 'nummod'],\n","  ['.', 'PUNCT', 'Z', 'O', 'punct'],\n","  ['v', 'ADP', 'Sl', 'O', 'case'],\n","  ['drug', 'ADJ', 'Mlpfsl', 'O', 'amod'],\n","  ['križevski', 'ADJ', 'Agpfsl', 'O', 'amod'],\n","  ['liga', 'NOUN', 'Ncfsl', 'O', 'obl'],\n","  ['biti', 'AUX', 'Va-r3s-n', 'O', 'aux'],\n","  ['vodilen', 'ADJ', 'Agpmsny', 'O', 'amod'],\n","  ['Cafe', 'PROPN', 'Npmsn', 'B-ORG', 'nmod'],\n","  ['del', 'NOUN', 'Ncmsn', 'I-ORG', 'nsubj'],\n","  ['mar', 'ADV', 'Rgp', 'I-ORG', 'advmod'],\n","  ['iz', 'ADP', 'Sg', 'O', 'case'],\n","  ['Vučji', 'ADJ', 'Agpfsg', 'B-LOC', 'amod'],\n","  ['vas', 'NOUN', 'Ncfsg', 'I-LOC', 'obl'],\n","  ['premagati', 'VERB', 'Vmep-sm', 'O', 'root'],\n","  ['montaža', 'NOUN', 'Ncfsa', 'B-ORG', 'obj'],\n","  ['Vrbnjak', 'PROPN', 'Npmsn', 'I-ORG', 'nmod'],\n","  ['iz', 'ADP', 'Sg', 'O', 'case'],\n","  ['star', 'ADJ', 'Agpfsg', 'B-LOC', 'amod'],\n","  ['nov', 'ADJ', 'Agpfsg', 'I-LOC', 'amod'],\n","  ['vas', 'NOUN', 'Ncfsg', 'I-LOC', 'nmod'],\n","  ['z', 'ADP', 'Si', 'O', 'case'],\n","  ['rezultat', 'NOUN', 'Ncmsi', 'O', 'nmod'],\n","  ['3:2', 'NUM', 'Mdc', 'O', 'nummod'],\n","  ['.', 'PUNCT', 'Z', 'O', 'punct'],\n","  ['oglasen', 'ADJ', 'Agpnsn', 'O', 'amod'],\n","  ['sporočilo', 'NOUN', 'Ncnsn', 'O', 'parataxis'],\n","  ['ocena', 'NOUN', 'Ncfsn', 'O', 'nmod']]}"]},"execution_count":49,"metadata":{},"output_type":"execute_result"}],"source":["# Import the file with additional text representations (only the paragraphs marked to be kept\n","# in the original corpus are included)\n","\n","with open(\"data/Language-Processed-GINCO.json\") as f:\n","    dataset = json.load(f)\n","\n","dataset[0]"]},{"cell_type":"code","execution_count":50,"metadata":{"execution":{"iopub.execute_input":"2022-02-11T10:15:38.007705Z","iopub.status.busy":"2022-02-11T10:15:38.007401Z","iopub.status.idle":"2022-02-11T10:15:38.013690Z","shell.execute_reply":"2022-02-11T10:15:38.012934Z","shell.execute_reply.started":"2022-02-11T10:15:38.007665Z"},"trusted":true},"outputs":[{"data":{"text/plain":["dict_keys(['id', 'url', 'crawled', 'hard', 'paragraphs', 'primary_level_1', 'primary_level_2', 'primary_level_3', 'secondary_level_1', 'secondary_level_2', 'secondary_level_3', 'tertiary_level_1', 'tertiary_level_2', 'tertiary_level_3', 'split', 'domain', 'baseline_text', 'no_of_words', 'lemmas', 'upos', 'xpos', 'ner', 'dependency', 'lowercase', 'lowercase_nopunctuation', 'representation_list'])"]},"execution_count":50,"metadata":{},"output_type":"execute_result"}],"source":["dataset[0].keys()"]},{"cell_type":"markdown","metadata":{},"source":["### Downcasting number of labels"]},{"cell_type":"markdown","metadata":{},"source":["In these experiments, we will not use all of the texts but only texts from 5 main categories, meaning that some categories will be merged into them, whereas some categories with a very small frequency will be discarded. Additionally, the texts marked us hard, will be discarded (see notebook *1-Preparing_Data_Hyperparameter_Search*).\n","\n","We will start with a reduced set of labels (primary_level_3), then merge News and Opinionated News, and discard some of the lables."]},{"cell_type":"code","execution_count":51,"metadata":{"execution":{"iopub.execute_input":"2022-02-11T10:15:57.239235Z","iopub.status.busy":"2022-02-11T10:15:57.238821Z","iopub.status.idle":"2022-02-11T10:15:57.246029Z","shell.execute_reply":"2022-02-11T10:15:57.245063Z","shell.execute_reply.started":"2022-02-11T10:15:57.239201Z"},"trusted":true},"outputs":[],"source":["# merge News and Opinionated News\n","for i in dataset:\n","    if i[\"primary_level_3\"] == \"Opinionated News\" or i[\"primary_level_3\"] == \"News/Reporting\":\n","        i[\"primary_level_3\"] = \"News\""]},{"cell_type":"markdown","metadata":{},"source":["Let's create train:test:dev split that contains only the wanted labels."]},{"cell_type":"code","execution_count":52,"metadata":{"execution":{"iopub.execute_input":"2022-02-11T10:16:02.432211Z","iopub.status.busy":"2022-02-11T10:16:02.431850Z","iopub.status.idle":"2022-02-11T10:16:02.444716Z","shell.execute_reply":"2022-02-11T10:16:02.443592Z","shell.execute_reply.started":"2022-02-11T10:16:02.432175Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["The train-dev-test splits consist of the following numbers of examples: 410 141 137\n"]}],"source":["downcasted_labels = ['Information/Explanation', 'Promotion', 'News', 'Forum', 'Opinion/Argumentation']\n","\n","train = [i for i in dataset if i[\"split\"] == \"train\" and i[\"primary_level_3\"] in downcasted_labels and not i[\"hard\"]]\n","test = [i for i in dataset if i[\"split\"] == \"test\" and i[\"primary_level_3\"] in downcasted_labels and not i[\"hard\"]]\n","dev = [i for i in dataset if i[\"split\"] == \"dev\" and i[\"primary_level_3\"] in downcasted_labels and not i[\"hard\"]]\n","\n","print(\"The train-dev-test splits consist of the following numbers of examples:\", len(train), len(test), len(dev))"]},{"cell_type":"code","execution_count":53,"metadata":{"execution":{"iopub.execute_input":"2022-02-11T10:16:10.634349Z","iopub.status.busy":"2022-02-11T10:16:10.633889Z","iopub.status.idle":"2022-02-11T10:16:10.639450Z","shell.execute_reply":"2022-02-11T10:16:10.638608Z","shell.execute_reply.started":"2022-02-11T10:16:10.634311Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Number of all texts is 688\n"]}],"source":["print(f\"Number of all texts is {len(train)+len(test)+len(dev)}\")"]},{"cell_type":"code","execution_count":54,"metadata":{},"outputs":[{"data":{"text/plain":["Index(['id', 'url', 'crawled', 'hard', 'paragraphs', 'primary_level_1',\n","       'primary_level_2', 'primary_level_3', 'secondary_level_1',\n","       'secondary_level_2', 'secondary_level_3', 'tertiary_level_1',\n","       'tertiary_level_2', 'tertiary_level_3', 'split', 'domain',\n","       'baseline_text', 'no_of_words', 'lemmas', 'upos', 'xpos', 'ner',\n","       'dependency', 'lowercase', 'lowercase_nopunctuation',\n","       'representation_list'],\n","      dtype='object')"]},"execution_count":54,"metadata":{},"output_type":"execute_result"}],"source":["# Create dataframes from the datasets\n","train_df = pd.DataFrame(train)\n","\n","train_df.columns"]},{"cell_type":"code","execution_count":55,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["test: (141, 26), dev: (137, 26)\n"]}],"source":["test_df = pd.DataFrame(test)\n","dev_df = pd.DataFrame(dev)\n","\n","print(f\"test: {test_df.shape}, dev: {dev_df.shape}\")"]},{"cell_type":"markdown","metadata":{},"source":["For the experiments, we'll use the baseline text (\"baseline_text\") and the \"primary_level_3\" labels."]},{"cell_type":"code","execution_count":56,"metadata":{},"outputs":[{"data":{"text/plain":["Index(['id', 'url', 'crawled', 'hard', 'paragraphs', 'primary_level_1',\n","       'primary_level_2', 'primary_level_3', 'secondary_level_1',\n","       'secondary_level_2', 'secondary_level_3', 'tertiary_level_1',\n","       'tertiary_level_2', 'tertiary_level_3', 'split', 'domain',\n","       'baseline_text', 'no_of_words', 'lemmas', 'upos', 'xpos', 'ner',\n","       'dependency', 'lowercase', 'lowercase_nopunctuation',\n","       'representation_list'],\n","      dtype='object')"]},"execution_count":56,"metadata":{},"output_type":"execute_result"}],"source":["train_df.columns"]},{"cell_type":"code","execution_count":64,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["410 410 141 141\n"]}],"source":["# Create X_train and Y_train parts, used for sci kit learning\n","# List of texts in training split\n","X_train = list(train_df.baseline_text)\n","# List of labels in training split\n","Y_train = list(train_df.primary_level_3)\n","\n","# List of texts in test split\n","X_test = list(test_df.baseline_text)\n","# List of labels in test split\n","Y_test = list(test_df.primary_level_3)\n","\n","print(len(X_train), len(Y_train), len(X_test), len(Y_test))"]},{"cell_type":"code","execution_count":65,"metadata":{},"outputs":[{"data":{"text/plain":["['News', 'News']"]},"execution_count":65,"metadata":{},"output_type":"execute_result"}],"source":["Y_test[:2]"]},{"cell_type":"code","execution_count":67,"metadata":{},"outputs":[{"data":{"text/plain":["['Information/Explanation',\n"," 'Promotion',\n"," 'News',\n"," 'Forum',\n"," 'Opinion/Argumentation']"]},"execution_count":67,"metadata":{},"output_type":"execute_result"}],"source":["# Create a list of labels\n","labels = list(train_df.primary_level_3.unique())\n","labels"]},{"cell_type":"code","execution_count":68,"metadata":{},"outputs":[],"source":["# Create a TF-IDF representation of the text\n","def data_iterator(f):\n","    for token in f:\n","        yield token\n","\n","\n","def tokenizer(txt):\n","    \"\"\"Simple whitespace tokenizer\"\"\"\n","    return txt.split()\n","\n","iterator=data_iterator(X_train)\n","test_iterator=data_iterator(X_test)\n","\n","vectorizer=sklearn.feature_extraction.text.TfidfVectorizer(tokenizer=tokenizer,use_idf=True,min_df=0.005)\n","\n","d=vectorizer.fit_transform(iterator)\n","\n","d_test=vectorizer.transform(test_iterator)"]},{"cell_type":"markdown","metadata":{"id":"Ewnh-3ZlmOF-"},"source":["## Training with various Sci-Kit models"]},{"cell_type":"code","execution_count":88,"metadata":{},"outputs":[],"source":["# Create a pipeline of models that you want to try:\n","\n","pipelines=[]\n","\n","\"\"\"\n","for model in [DummyClassifier(strategy=\"most_frequent\"), DummyClassifier(strategy=\"stratified\"), DecisionTreeClassifier(), MultinomialNB(), ComplementNB(), LogisticRegression(solver='saga'), SVC(C=0.5,kernel='linear',shrinking=False,probability=True),RandomForestClassifier()]:\n","    pipeline=make_pipeline(model)\n","    pipelines.append(pipeline)\n","\n","\"\"\"\n","\n","for model in [DummyClassifier(strategy=\"most_frequent\"), DummyClassifier(strategy=\"stratified\"), DecisionTreeClassifier(), MultinomialNB(), ComplementNB(), LogisticRegression(), SVC(),RandomForestClassifier()]:\n","    pipeline=make_pipeline(model)\n","    pipelines.append(pipeline)"]},{"cell_type":"code","execution_count":89,"metadata":{},"outputs":[{"data":{"text/plain":["[Pipeline(steps=[('dummyclassifier', DummyClassifier(strategy='most_frequent'))]),\n"," Pipeline(steps=[('dummyclassifier', DummyClassifier(strategy='stratified'))]),\n"," Pipeline(steps=[('decisiontreeclassifier', DecisionTreeClassifier())]),\n"," Pipeline(steps=[('multinomialnb', MultinomialNB())]),\n"," Pipeline(steps=[('complementnb', ComplementNB())]),\n"," Pipeline(steps=[('logisticregression', LogisticRegression())]),\n"," Pipeline(steps=[('svc', SVC())]),\n"," Pipeline(steps=[('randomforestclassifier', RandomForestClassifier())])]"]},"execution_count":89,"metadata":{},"output_type":"execute_result"}],"source":["pipelines"]},{"cell_type":"code","execution_count":90,"metadata":{},"outputs":[],"source":["for i, pipeline in enumerate(pipelines):\n","    pipeline.fit(d, Y_train)"]},{"cell_type":"code","execution_count":91,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Classifiation Report\n","\n","*****************************************************\n","DUMMYCLASSIFIER\n","\n","                          precision    recall  f1-score   support\n","\n","                  Forum       0.00      0.00      0.00         9\n","Information/Explanation       0.00      0.00      0.00        33\n","                   News       0.00      0.00      0.00        46\n","  Opinion/Argumentation       0.00      0.00      0.00        19\n","              Promotion       0.24      1.00      0.39        34\n","\n","               accuracy                           0.24       141\n","              macro avg       0.05      0.20      0.08       141\n","           weighted avg       0.06      0.24      0.09       141\n","\n","*****************************************************\n","DUMMYCLASSIFIER\n","\n","                          precision    recall  f1-score   support\n","\n","                  Forum       0.10      0.11      0.11         9\n","Information/Explanation       0.11      0.06      0.08        33\n","                   News       0.40      0.39      0.40        46\n","  Opinion/Argumentation       0.13      0.21      0.16        19\n","              Promotion       0.35      0.38      0.37        34\n","\n","               accuracy                           0.27       141\n","              macro avg       0.22      0.23      0.22       141\n","           weighted avg       0.26      0.27      0.26       141\n","\n","*****************************************************\n","DECISIONTREECLASSIFIER\n","\n","                          precision    recall  f1-score   support\n","\n","                  Forum       0.44      0.44      0.44         9\n","Information/Explanation       0.32      0.21      0.25        33\n","                   News       0.43      0.33      0.37        46\n","  Opinion/Argumentation       0.30      0.37      0.33        19\n","              Promotion       0.29      0.44      0.35        34\n","\n","               accuracy                           0.34       141\n","              macro avg       0.36      0.36      0.35       141\n","           weighted avg       0.35      0.34      0.34       141\n","\n","*****************************************************\n","MULTINOMIALNB\n","\n","                          precision    recall  f1-score   support\n","\n","                  Forum       0.00      0.00      0.00         9\n","Information/Explanation       0.00      0.00      0.00        33\n","                   News       0.51      0.76      0.61        46\n","  Opinion/Argumentation       0.31      0.42      0.36        19\n","              Promotion       0.64      0.88      0.74        34\n","\n","               accuracy                           0.52       141\n","              macro avg       0.29      0.41      0.34       141\n","           weighted avg       0.36      0.52      0.43       141\n","\n","*****************************************************\n","COMPLEMENTNB\n","\n","                          precision    recall  f1-score   support\n","\n","                  Forum       0.00      0.00      0.00         9\n","Information/Explanation       0.78      0.21      0.33        33\n","                   News       0.57      0.65      0.61        46\n","  Opinion/Argumentation       0.28      0.58      0.37        19\n","              Promotion       0.72      0.82      0.77        34\n","\n","               accuracy                           0.54       141\n","              macro avg       0.47      0.45      0.42       141\n","           weighted avg       0.58      0.54      0.51       141\n","\n","*****************************************************\n","LOGISTICREGRESSION\n","\n","                          precision    recall  f1-score   support\n","\n","                  Forum       0.00      0.00      0.00         9\n","Information/Explanation       0.83      0.15      0.26        33\n","                   News       0.54      0.63      0.58        46\n","  Opinion/Argumentation       0.39      0.47      0.43        19\n","              Promotion       0.52      0.88      0.65        34\n","\n","               accuracy                           0.52       141\n","              macro avg       0.46      0.43      0.38       141\n","           weighted avg       0.55      0.52      0.46       141\n","\n","*****************************************************\n","SVC\n","\n","                          precision    recall  f1-score   support\n","\n","                  Forum       0.00      0.00      0.00         9\n","Information/Explanation       1.00      0.03      0.06        33\n","                   News       0.53      0.65      0.58        46\n","  Opinion/Argumentation       0.38      0.42      0.40        19\n","              Promotion       0.48      0.88      0.62        34\n","\n","               accuracy                           0.49       141\n","              macro avg       0.48      0.40      0.33       141\n","           weighted avg       0.57      0.49      0.41       141\n","\n","*****************************************************\n","RANDOMFORESTCLASSIFIER\n","\n","                          precision    recall  f1-score   support\n","\n","                  Forum       1.00      0.11      0.20         9\n","Information/Explanation       0.75      0.09      0.16        33\n","                   News       0.54      0.63      0.58        46\n","  Opinion/Argumentation       0.50      0.47      0.49        19\n","              Promotion       0.47      0.88      0.61        34\n","\n","               accuracy                           0.51       141\n","              macro avg       0.65      0.44      0.41       141\n","           weighted avg       0.59      0.51      0.45       141\n","\n","*****************************************************\n"]}],"source":["#Prediction from test dataset\n","model_name=[]\n","y_pred_list = []\n","micro_f1_array=[]\n","macro_f1_array = []\n","accuracy_array = []\n","\n","print(\"Classifiation Report\\n\")\n","print(\"*****************************************************\")\n","for i, pipeline in enumerate(pipelines):\n","    y_pred=pipeline.predict(d_test)\n","    y_pred_list.append(list(y_pred))\n","    print(pipelines[i].steps[0][0].upper())\n","    model_name.append(pipelines[i].steps[0][0].upper())\n","\n","    micro_f1_array.append(round(f1_score(Y_test, y_pred, labels=labels, average =\"micro\"),3))\n","    macro_f1_array.append(round(f1_score(Y_test, y_pred, labels=labels, average =\"macro\"),3))\n","    accuracy_array.append(round(metrics.accuracy_score(Y_test, y_pred),3))\n","    print(\"\\n\",classification_report(Y_test, y_pred, zero_division = 0))\n","    print(\"*****************************************************\")\n","\n","results = {\"model\":model_name, \"microF1\": micro_f1_array, \"macroF1\":macro_f1_array, \"accuracy\":accuracy_array, \"y_pred\":y_pred_list}"]},{"cell_type":"code","execution_count":92,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>model</th>\n","      <th>microF1</th>\n","      <th>macroF1</th>\n","      <th>accuracy</th>\n","      <th>y_pred</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>DUMMYCLASSIFIER</td>\n","      <td>0.241</td>\n","      <td>0.078</td>\n","      <td>0.241</td>\n","      <td>[Promotion, Promotion, Promotion, Promotion, P...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>DUMMYCLASSIFIER</td>\n","      <td>0.270</td>\n","      <td>0.221</td>\n","      <td>0.270</td>\n","      <td>[Promotion, News, Promotion, Opinion/Argumenta...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>DECISIONTREECLASSIFIER</td>\n","      <td>0.340</td>\n","      <td>0.350</td>\n","      <td>0.340</td>\n","      <td>[Opinion/Argumentation, Promotion, Promotion, ...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>MULTINOMIALNB</td>\n","      <td>0.518</td>\n","      <td>0.342</td>\n","      <td>0.518</td>\n","      <td>[News, News, Promotion, Promotion, News, Opini...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>COMPLEMENTNB</td>\n","      <td>0.539</td>\n","      <td>0.416</td>\n","      <td>0.539</td>\n","      <td>[News, News, Promotion, Promotion, News, Opini...</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>LOGISTICREGRESSION</td>\n","      <td>0.518</td>\n","      <td>0.383</td>\n","      <td>0.518</td>\n","      <td>[News, Promotion, Promotion, Promotion, News, ...</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>SVC</td>\n","      <td>0.489</td>\n","      <td>0.333</td>\n","      <td>0.489</td>\n","      <td>[News, Promotion, Promotion, Promotion, News, ...</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>RANDOMFORESTCLASSIFIER</td>\n","      <td>0.511</td>\n","      <td>0.408</td>\n","      <td>0.511</td>\n","      <td>[News, Promotion, Promotion, Information/Expla...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                    model  microF1  macroF1  accuracy  \\\n","0         DUMMYCLASSIFIER    0.241    0.078     0.241   \n","1         DUMMYCLASSIFIER    0.270    0.221     0.270   \n","2  DECISIONTREECLASSIFIER    0.340    0.350     0.340   \n","3           MULTINOMIALNB    0.518    0.342     0.518   \n","4            COMPLEMENTNB    0.539    0.416     0.539   \n","5      LOGISTICREGRESSION    0.518    0.383     0.518   \n","6                     SVC    0.489    0.333     0.489   \n","7  RANDOMFORESTCLASSIFIER    0.511    0.408     0.511   \n","\n","                                              y_pred  \n","0  [Promotion, Promotion, Promotion, Promotion, P...  \n","1  [Promotion, News, Promotion, Opinion/Argumenta...  \n","2  [Opinion/Argumentation, Promotion, Promotion, ...  \n","3  [News, News, Promotion, Promotion, News, Opini...  \n","4  [News, News, Promotion, Promotion, News, Opini...  \n","5  [News, Promotion, Promotion, Promotion, News, ...  \n","6  [News, Promotion, Promotion, Promotion, News, ...  \n","7  [News, Promotion, Promotion, Information/Expla...  "]},"execution_count":92,"metadata":{},"output_type":"execute_result"}],"source":["results_df = pd.DataFrame(results)\n","results_df"]},{"cell_type":"code","execution_count":93,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>model</th>\n","      <th>microF1</th>\n","      <th>macroF1</th>\n","      <th>accuracy</th>\n","      <th>y_pred</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>DUMMYCLASSIFIER</td>\n","      <td>0.241</td>\n","      <td>0.078</td>\n","      <td>0.241</td>\n","      <td>[Promotion, Promotion, Promotion, Promotion, P...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>DUMMYCLASSIFIER</td>\n","      <td>0.270</td>\n","      <td>0.221</td>\n","      <td>0.270</td>\n","      <td>[Promotion, News, Promotion, Opinion/Argumenta...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>DECISIONTREECLASSIFIER</td>\n","      <td>0.340</td>\n","      <td>0.350</td>\n","      <td>0.340</td>\n","      <td>[Opinion/Argumentation, Promotion, Promotion, ...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>MULTINOMIALNB</td>\n","      <td>0.518</td>\n","      <td>0.342</td>\n","      <td>0.518</td>\n","      <td>[News, News, Promotion, Promotion, News, Opini...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>COMPLEMENTNB</td>\n","      <td>0.539</td>\n","      <td>0.416</td>\n","      <td>0.539</td>\n","      <td>[News, News, Promotion, Promotion, News, Opini...</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>LOGISTICREGRESSION</td>\n","      <td>0.518</td>\n","      <td>0.383</td>\n","      <td>0.518</td>\n","      <td>[News, Promotion, Promotion, Promotion, News, ...</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>SVC</td>\n","      <td>0.489</td>\n","      <td>0.333</td>\n","      <td>0.489</td>\n","      <td>[News, Promotion, Promotion, Promotion, News, ...</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>RANDOMFORESTCLASSIFIER</td>\n","      <td>0.511</td>\n","      <td>0.408</td>\n","      <td>0.511</td>\n","      <td>[News, Promotion, Promotion, Information/Expla...</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>FastText</td>\n","      <td>0.560</td>\n","      <td>0.589</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                    model  microF1  macroF1  accuracy  \\\n","0         DUMMYCLASSIFIER    0.241    0.078     0.241   \n","1         DUMMYCLASSIFIER    0.270    0.221     0.270   \n","2  DECISIONTREECLASSIFIER    0.340    0.350     0.340   \n","3           MULTINOMIALNB    0.518    0.342     0.518   \n","4            COMPLEMENTNB    0.539    0.416     0.539   \n","5      LOGISTICREGRESSION    0.518    0.383     0.518   \n","6                     SVC    0.489    0.333     0.489   \n","7  RANDOMFORESTCLASSIFIER    0.511    0.408     0.511   \n","8                FastText    0.560    0.589       NaN   \n","\n","                                              y_pred  \n","0  [Promotion, Promotion, Promotion, Promotion, P...  \n","1  [Promotion, News, Promotion, Opinion/Argumenta...  \n","2  [Opinion/Argumentation, Promotion, Promotion, ...  \n","3  [News, News, Promotion, Promotion, News, Opini...  \n","4  [News, News, Promotion, Promotion, News, Opini...  \n","5  [News, Promotion, Promotion, Promotion, News, ...  \n","6  [News, Promotion, Promotion, Promotion, News, ...  \n","7  [News, Promotion, Promotion, Information/Expla...  \n","8                                                NaN  "]},"execution_count":93,"metadata":{},"output_type":"execute_result"}],"source":["# Append the results for the FastText model\n","\n","ft = {\"model\": \"FastText\", \"microF1\": 0.56, \"macroF1\": 0.589}\n","\n","results_df = results_df.append(ft, ignore_index = True)\n","\n","results_df\n","\n"]},{"cell_type":"code","execution_count":94,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["| model                  |   microF1 |   macroF1 |\n","|:-----------------------|----------:|----------:|\n","| DUMMYCLASSIFIER        |     0.241 |     0.078 |\n","| DUMMYCLASSIFIER        |     0.27  |     0.221 |\n","| DECISIONTREECLASSIFIER |     0.34  |     0.35  |\n","| MULTINOMIALNB          |     0.518 |     0.342 |\n","| COMPLEMENTNB           |     0.539 |     0.416 |\n","| LOGISTICREGRESSION     |     0.518 |     0.383 |\n","| SVC                    |     0.489 |     0.333 |\n","| RANDOMFORESTCLASSIFIER |     0.511 |     0.408 |\n","| FastText               |     0.56  |     0.589 |\n"]}],"source":["# Show in markdown\n","print(results_df[[\"model\",\"microF1\", \"macroF1\"]].to_markdown(index = False))"]},{"cell_type":"code","execution_count":95,"metadata":{},"outputs":[],"source":["# Save the results in a csv format\n","results_df.to_csv(\"results/additional_models_experiments.csv\")"]}],"metadata":{"kernelspec":{"display_name":"Python 3.10.2 64-bit","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.2"},"vscode":{"interpreter":{"hash":"4054637ba3b142bc5aa565ef637e29d85952330aa10ad5bd25955ba00ae91bfa"}}},"nbformat":4,"nbformat_minor":4}
