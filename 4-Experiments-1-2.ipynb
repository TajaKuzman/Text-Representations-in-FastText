{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Learning on various text representations - shortened"]},{"cell_type":"markdown","metadata":{},"source":["This notebook was used to ran all of the experiments, based on the functions, defined in the utility scripts at the beginning of the file. To inspect step-by-step procedure, see the *3-Learning-On-Various_Representations.ipynb* file."]},{"cell_type":"markdown","metadata":{},"source":["## Preparing the dataset for FastText"]},{"cell_type":"markdown","metadata":{},"source":["Importing the necessary libraries"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-02-17T07:53:05.882134Z","iopub.status.busy":"2022-02-17T07:53:05.881471Z","iopub.status.idle":"2022-02-17T07:53:19.534355Z","shell.execute_reply":"2022-02-17T07:53:19.533351Z","shell.execute_reply.started":"2022-02-17T07:53:05.882037Z"},"trusted":true},"outputs":[],"source":["!pip install parse"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-02-17T07:53:19.536555Z","iopub.status.busy":"2022-02-17T07:53:19.536312Z","iopub.status.idle":"2022-02-17T07:53:20.659237Z","shell.execute_reply":"2022-02-17T07:53:20.658387Z","shell.execute_reply.started":"2022-02-17T07:53:19.536526Z"},"trusted":true},"outputs":[],"source":["import json\n","import pandas as pd\n","from copy import deepcopy\n","import re\n","from tqdm import tqdm\n","import fasttext as ft\n","import parse\n","import numpy as np\n","from sklearn.metrics import f1_score\n","from sklearn.metrics import confusion_matrix\n","import matplotlib.pyplot as plt"]},{"cell_type":"markdown","metadata":{},"source":["Add all utility scripts:"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-02-17T07:53:20.661467Z","iopub.status.busy":"2022-02-17T07:53:20.661092Z","iopub.status.idle":"2022-02-17T07:53:20.694859Z","shell.execute_reply":"2022-02-17T07:53:20.693883Z","shell.execute_reply.started":"2022-02-17T07:53:20.661429Z"},"trusted":true},"outputs":[],"source":["# Creating FastText train and test files\n","\n","\n","def fastText_files(representation):\n","    \"\"\"\n","    This function creates and saves the test and train file\n","    from the test, train and dev split of the dataset (named test, dev and train),\n","    using the \"primary_level_3\" level labels, and the chosen text representation.\n","    \n","    Possible representations: 'baseline_text', 'lemmas',\n","    'upos', 'xpos', 'ner', 'dependency', 'lowercase', 'lowercase_nopunctuation'\n","    \n","    The function returns a list of the following elements:\n","        - labels - which can be used for prediction and evaluation.\n","        - train file path\n","        - test file path\n","    \n","    Args:\n","        representation (str): the name of the key (from the dataset)\n","                                of the text representation we want to use\n","    \"\"\"\n","    # First create the dataframes from each split:\n","    \n","    train_df = pd.DataFrame(data=train, columns=[representation, \"primary_level_3\"])\n","    # Renaming columns to `text` and `labels`\n","    train_df.columns = [\"text\", \"labels\"]\n","    \n","    test_df = pd.DataFrame(data=test, columns=[representation, \"primary_level_3\"])\n","    test_df.columns = [\"text\", \"labels\"]\n","    \n","    print(\"The shape of the dataframes:\")\n","    print(train_df.shape, test_df.shape)\n","    \n","    # Then create CSV files which FastText can read\n","    \n","    train_file_content=\"\"\n","\n","    for labels, text in train_df.loc[:, [\"labels\", \"text\"]].values:\n","        label = f\"__label__{labels}\"\n","        train_file_content += f\"\"\"{label} {text}\\n\"\"\"\n","    \n","    train_path = \"\"\n","    train_path = representation + \"-fasttext.train\"\n","\n","    with open(train_path,\"w\") as train_file:\n","        train_file.write(train_file_content)\n","    \n","    train_example = open(train_path,\"r\").read(1000)\n","    print(\"Created train file:\")\n","    print(train_example)\n","    \n","    test_file_content=\"\"\n","    \n","    for labels, text in test_df.loc[:, [\"labels\", \"text\"]].values:\n","        label = f\"__label__{labels}\"\n","        test_file_content += f\"\"\"{label} {text}\\n\"\"\"\n","    \n","    test_path = \"\"\n","    test_path = representation + \"-fasttext.test\"\n","    \n","    with open(test_path,\"w\") as test_file:\n","        test_file.write(test_file_content)\n","    \n","    test_example = open(test_path,\"r\").read(1000)\n","    print(\"Created test file:\")\n","    print(test_example)\n","    \n","    \n","    # Finally, create a list of labels which can be used for prediction and evaluation.\n","    # Let's inspect the labels:\n","    all_df_labels = train_df[\"labels\"].unique().tolist()\n","    \n","    for i in test_df[\"labels\"].unique().tolist():\n","        if i not in all_df_labels:\n","            all_df_labels.append(i)\n","\n","    print(f\"Number of all labels: {len(all_df_labels)}\")\n","    \n","    # Create a final list of labels in a FastText-appropriate format:\n","    LABELS = train_df.labels.unique().tolist()\n","    LABELS = [f\"__label__{i}\" for i in LABELS]\n","    \n","    return_list = [LABELS, train_path, test_path]\n","    print(f\"The function returned the following list: {return_list}\")\n","    \n","    return return_list\n","\n","# Parsing test file\n","def parse_test_file(path: str):\n","    \"\"\"Reads fasttext formatted file and returns labels, texts.\"\"\"\n","    with open(path, \"r\") as f:\n","        content = f.readlines()\n","    pattern = \"{label} {text}\\n\"\n","    p = parse.compile(pattern)\n","\n","    labels, texts = list(), list()\n","    for line in content:\n","        rez = p.parse(line)\n","        if rez is not None:\n","            labels.append(rez[\"label\"])\n","            texts.append(rez[\"text\"])\n","        else:\n","            print(\"error parsing line \", line)\n","    return labels, texts\n","\n","def prediction_to_label(prediction):\n","    \"\"\"Transforms predictions as returned by fasttext into pure labels.\"\"\"\n","    return np.array(prediction[0])[:, 0]\n","\n","def train_FastText(representation):\n","    \"\"\"\n","    The function uses the created FT_train_file and FT_test_file\n","    and performs five runs of training and evaluation of the model.\n","    It plots a confusion matrix for each run.\n","\n","    Args:\n","        representation (str): the name of the key (from the dataset)\n","                                of the text representation we want to use\n","    \n","    \"\"\"\n","    results = []\n","\n","    for i in range(5):\n","        model = ft.train_supervised(input=FT_train_file,\n","                                    epoch = 350,\n","                                    lr = 0.7,\n","                                    wordNgrams=1,\n","                                    verbose = 2\n","                                                )\n","        # Parse the test files so that labels and texts are separated\n","        y_true, y_texts = parse_test_file(FT_test_file)\n","\n","        # Evaluate the model on test data\n","        y_pred = model.predict(y_texts)\n","        y_pred = prediction_to_label(y_pred)\n","\n","        # Plot the confusion matrix:\n","        cm = confusion_matrix(y_true, y_pred, labels=LABELS)\n","        plt.figure(figsize=(9, 9))\n","        plt.imshow(cm, cmap=\"Oranges\")\n","        classNames = LABELS\n","        plt.ylabel('True label')\n","        plt.xlabel('Predicted label')\n","        tick_marks = np.arange(len(classNames))\n","        plt.xticks(tick_marks, classNames, rotation=90)\n","        plt.yticks(tick_marks, classNames)\n","        \n","        m = f1_score(y_true, y_pred, labels=LABELS, average =\"micro\")\n","        M = f1_score(y_true, y_pred, labels=LABELS, average =\"macro\")\n","        score_per_label = list(f1_score(y_true, y_pred, labels=LABELS, average=None))\n","        \n","        dict_score_per_label = {}\n","        \n","        for index in range(len(LABELS)):\n","            dict_score_per_label[LABELS[index]] = score_per_label[index]\n","             \n","        print(f\"Score per labels: {dict_score_per_label}\")\n","\n","        metrics = f\"{m:0.4}, {M:0.4}\"\n","        title = f\"Representation: {representation}, Run: {i}\"\n","        plt.title(title +\";\\n\" + metrics)\n","        plt.tight_layout()\n","        plt.savefig(title)\n","        plt.show()\n","        \n","        rezdict = {}\n","        \n","        rezdict = {\n","            \"microF1\": m,\n","            \"macroF1\": M,\n","            \"label_scores\": dict_score_per_label,\n","            \"run\": i,\n","            \"experiment\": representation,\n","        }\n","        results.append(rezdict)\n","        final_results.append(rezdict)\n","    \n","    # Calculate the average micro and macro F1 for the 5 runs:\n","    mi = []\n","    ma = []\n","    \n","    for i in results:\n","        mi.append(i['microF1'])\n","        ma.append(i[\"macroF1\"])\n","\n","    print(f\"micro F1: {np.array(mi).mean():0.03} +/- {np.array(mi).std():0.02}\")\n","    print(f\"macro F1: {np.array(ma).mean():0.03} +/- {np.array(ma).std():0.02}\")\n","    "]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-02-17T07:53:20.697356Z","iopub.status.busy":"2022-02-17T07:53:20.697088Z","iopub.status.idle":"2022-02-17T07:53:22.260451Z","shell.execute_reply":"2022-02-17T07:53:22.259406Z","shell.execute_reply.started":"2022-02-17T07:53:20.697315Z"},"executionInfo":{"elapsed":389,"status":"ok","timestamp":1640949108560,"user":{"displayName":"Taja Kuzman","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16199926972677634189"},"user_tz":-60},"id":"qL9iYqif_lSk","trusted":true},"outputs":[],"source":["# Import the file with additional text representations (only the paragraphs marked to be kept\n","# in the original corpus are included)\n","\n","with open(\"/kaggle/input/ginco-with-additional-text-representations/Language-Processed-GINCO.json\") as f:\n","    dataset = json.load(f)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-02-17T07:53:22.262745Z","iopub.status.busy":"2022-02-17T07:53:22.261892Z","iopub.status.idle":"2022-02-17T07:53:22.273488Z","shell.execute_reply":"2022-02-17T07:53:22.272611Z","shell.execute_reply.started":"2022-02-17T07:53:22.262699Z"},"trusted":true},"outputs":[],"source":["dataset[0].keys()"]},{"cell_type":"markdown","metadata":{},"source":["### Pre-processing dataset"]},{"cell_type":"markdown","metadata":{},"source":["Here we can create additional representations if we wish (see the notebook *2-Language-Processing-of-GINCO*)."]},{"cell_type":"markdown","metadata":{},"source":["1. Remove punctuation from each token"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-02-17T07:53:22.275338Z","iopub.status.busy":"2022-02-17T07:53:22.275028Z","iopub.status.idle":"2022-02-17T07:53:22.575153Z","shell.execute_reply":"2022-02-17T07:53:22.574358Z","shell.execute_reply.started":"2022-02-17T07:53:22.275288Z"},"trusted":true},"outputs":[],"source":["from string import punctuation\n","\n","for instance in tqdm(dataset):\n","        text = instance[\"baseline_text\"]\n","        \n","        # split text into tokens by white space\n","        token = text.split()\n","         \n","        # remove punctuation from each token\n","        table = str.maketrans('', '', punctuation)\n","        token = [word.translate(table) for word in token]\n","\n","        # add a new key with punctuation removed\n","        instance[\"nopunctuation\"] = \" \".join(token)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-02-17T07:53:22.576596Z","iopub.status.busy":"2022-02-17T07:53:22.576376Z","iopub.status.idle":"2022-02-17T07:53:22.596389Z","shell.execute_reply":"2022-02-17T07:53:22.595358Z","shell.execute_reply.started":"2022-02-17T07:53:22.57657Z"},"trusted":true},"outputs":[],"source":["dataset[0]"]},{"cell_type":"markdown","metadata":{},"source":["2. Remove numbers from each token"]},{"cell_type":"code","execution_count":null,"metadata":{"_kg_hide-output":true,"execution":{"iopub.execute_input":"2022-02-17T09:01:13.016558Z","iopub.status.busy":"2022-02-17T09:01:13.016257Z","iopub.status.idle":"2022-02-17T09:01:13.264211Z","shell.execute_reply":"2022-02-17T09:01:13.263343Z","shell.execute_reply.started":"2022-02-17T09:01:13.016525Z"},"trusted":true},"outputs":[],"source":["from string import digits\n","\n","for instance in tqdm(dataset):\n","        text = instance[\"baseline_text\"]\n","\n","        # remove digits from each token\n","        remove_digits = str.maketrans('', '', digits)\n","        text_no_digits = text.translate(remove_digits)\n","\n","        # add a new key with digits removed\n","        instance[\"nonumbers\"] = text_no_digits\n","        \n","dataset[-1]"]},{"cell_type":"markdown","metadata":{},"source":["4. Apply all (lowercase, remove punctuation, numbers)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-02-17T09:32:54.436692Z","iopub.status.busy":"2022-02-17T09:32:54.435808Z","iopub.status.idle":"2022-02-17T09:32:54.978938Z","shell.execute_reply":"2022-02-17T09:32:54.977865Z","shell.execute_reply.started":"2022-02-17T09:32:54.43665Z"},"trusted":true},"outputs":[],"source":["# Let's apply punctuation and number removal on the lowercase text.\n","\n","for instance in tqdm(dataset):\n","        text = instance['lowercase']\n","        \n","        # split text into tokens by white space\n","        token = text.split()\n","         \n","        # remove punctuation from each token\n","        table = str.maketrans('', '', punctuation)\n","        token = [word.translate(table) for word in token]\n","\n","        text_no_punctuation = \" \".join(token)\n","        \n","        # remove digits from each token\n","        remove_digits = str.maketrans('', '', digits)\n","        text_no_digits = text_no_punctuation.translate(remove_digits)\n","\n","        # add a new key with lowercase text with punctuation and digits removed\n","        instance[\"lowercase_nopunct_nodigits\"] = text_no_digits\n","\n","dataset[-1]"]},{"cell_type":"markdown","metadata":{},"source":["### Downcasting number of labels"]},{"cell_type":"markdown","metadata":{},"source":["In these experiments, we will not use all of the texts but only texts from 5 main categories, meaning that some categories will be merged into them, whereas some categories with a very small frequency will be discarded. Additionally, the texts marked us hard, will be discarded (see notebook *1-Preparing_Data_Hyperparameter_Search*).\n","\n","We will start with a reduced set of labels (primary_level_3), then merge News and Opinionated News, and discard some of the lables."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-02-17T09:33:22.889569Z","iopub.status.busy":"2022-02-17T09:33:22.888953Z","iopub.status.idle":"2022-02-17T09:33:22.897759Z","shell.execute_reply":"2022-02-17T09:33:22.896454Z","shell.execute_reply.started":"2022-02-17T09:33:22.889511Z"},"trusted":true},"outputs":[],"source":["# merge News and Opinionated News\n","for i in dataset:\n","    if i[\"primary_level_3\"] == \"Opinionated News\" or i[\"primary_level_3\"] == \"News/Reporting\":\n","        i[\"primary_level_3\"] = \"News\""]},{"cell_type":"markdown","metadata":{},"source":["Let's create train:test:dev split that contains only the wanted labels."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-02-17T09:33:22.901782Z","iopub.status.busy":"2022-02-17T09:33:22.901002Z","iopub.status.idle":"2022-02-17T09:33:22.918049Z","shell.execute_reply":"2022-02-17T09:33:22.916886Z","shell.execute_reply.started":"2022-02-17T09:33:22.901711Z"},"trusted":true},"outputs":[],"source":["downcasted_labels = ['Information/Explanation', 'Promotion', 'News', 'Forum', 'Opinion/Argumentation']\n","\n","train = [i for i in dataset if i[\"split\"] == \"train\" and i[\"primary_level_3\"] in downcasted_labels and not i[\"hard\"]]\n","test = [i for i in dataset if i[\"split\"] == \"test\" and i[\"primary_level_3\"] in downcasted_labels and not i[\"hard\"]]\n","dev = [i for i in dataset if i[\"split\"] == \"dev\" and i[\"primary_level_3\"] in downcasted_labels and not i[\"hard\"]]\n","\n","print(\"The train-dev-test splits consist of the following numbers of examples:\", len(train), len(test), len(dev))"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-02-17T09:33:22.920073Z","iopub.status.busy":"2022-02-17T09:33:22.919344Z","iopub.status.idle":"2022-02-17T09:33:22.932585Z","shell.execute_reply":"2022-02-17T09:33:22.931452Z","shell.execute_reply.started":"2022-02-17T09:33:22.920032Z"},"trusted":true},"outputs":[],"source":["print(f\"Number of all texts is {len(train)+len(test)+len(dev)}\")"]},{"cell_type":"markdown","metadata":{},"source":["### Creating FastText texts"]},{"cell_type":"markdown","metadata":{"id":"xw1ugH8i6KuD"},"source":["Use the function fastText_files(representation) from the utility functions.\n","\n","This function creates and saves the test and train file\n","    from the test, train and dev split of the dataset (named test, dev and train),\n","    using the \"primary_level_3\" level labels, and the chosen text representation."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-02-17T09:33:58.729787Z","iopub.status.busy":"2022-02-17T09:33:58.729347Z","iopub.status.idle":"2022-02-17T09:33:58.735705Z","shell.execute_reply":"2022-02-17T09:33:58.734804Z","shell.execute_reply.started":"2022-02-17T09:33:58.729748Z"},"trusted":true},"outputs":[],"source":["dataset[0].keys()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-02-17T09:59:18.878014Z","iopub.status.busy":"2022-02-17T09:59:18.877623Z","iopub.status.idle":"2022-02-17T09:59:18.883599Z","shell.execute_reply":"2022-02-17T09:59:18.882336Z","shell.execute_reply.started":"2022-02-17T09:59:18.877973Z"},"trusted":true},"outputs":[],"source":["current_representation = 'ner'"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-02-17T09:59:20.775877Z","iopub.status.busy":"2022-02-17T09:59:20.77553Z","iopub.status.idle":"2022-02-17T09:59:20.780297Z","shell.execute_reply":"2022-02-17T09:59:20.779275Z","shell.execute_reply.started":"2022-02-17T09:59:20.77584Z"},"trusted":true},"outputs":[],"source":["final_results = list()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-02-17T09:59:23.359928Z","iopub.status.busy":"2022-02-17T09:59:23.359384Z","iopub.status.idle":"2022-02-17T09:59:23.382687Z","shell.execute_reply":"2022-02-17T09:59:23.381654Z","shell.execute_reply.started":"2022-02-17T09:59:23.359855Z"},"trusted":true},"outputs":[],"source":["representation = fastText_files(current_representation)"]},{"cell_type":"markdown","metadata":{"id":"QB0_-1xIRPx-"},"source":["# Train a fastText model"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-02-17T09:59:31.653954Z","iopub.status.busy":"2022-02-17T09:59:31.653618Z","iopub.status.idle":"2022-02-17T09:59:31.660242Z","shell.execute_reply":"2022-02-17T09:59:31.659417Z","shell.execute_reply.started":"2022-02-17T09:59:31.653894Z"},"trusted":true},"outputs":[],"source":["# Define the label list:\n","LABELS = representation[0]\n","\n","LABELS"]},{"cell_type":"markdown","metadata":{},"source":["Input the data:"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-02-17T09:59:31.662476Z","iopub.status.busy":"2022-02-17T09:59:31.661733Z","iopub.status.idle":"2022-02-17T09:59:31.672159Z","shell.execute_reply":"2022-02-17T09:59:31.671216Z","shell.execute_reply.started":"2022-02-17T09:59:31.662432Z"},"id":"s3ytA4GWVVhk","trusted":true},"outputs":[],"source":["FT_train_file = representation[1]\n","FT_test_file = representation[2]"]},{"cell_type":"markdown","metadata":{},"source":["Use the train_FastText(representation) function from utils.py"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-02-17T09:59:31.673841Z","iopub.status.busy":"2022-02-17T09:59:31.673247Z","iopub.status.idle":"2022-02-17T10:00:07.313125Z","shell.execute_reply":"2022-02-17T10:00:07.31211Z","shell.execute_reply.started":"2022-02-17T09:59:31.673806Z"},"trusted":true},"outputs":[],"source":["train_FastText(current_representation)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-02-17T10:00:07.315078Z","iopub.status.busy":"2022-02-17T10:00:07.314693Z","iopub.status.idle":"2022-02-17T10:00:07.322078Z","shell.execute_reply":"2022-02-17T10:00:07.320981Z","shell.execute_reply.started":"2022-02-17T10:00:07.315029Z"},"trusted":true},"outputs":[],"source":["len(final_results)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-02-17T10:00:07.32527Z","iopub.status.busy":"2022-02-17T10:00:07.324463Z","iopub.status.idle":"2022-02-17T10:00:07.336861Z","shell.execute_reply":"2022-02-17T10:00:07.335956Z","shell.execute_reply.started":"2022-02-17T10:00:07.325224Z"},"trusted":true},"outputs":[],"source":["print(final_results[0])\n","print(final_results[-1])"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-02-17T10:01:08.933294Z","iopub.status.busy":"2022-02-17T10:01:08.932957Z","iopub.status.idle":"2022-02-17T10:01:08.937888Z","shell.execute_reply":"2022-02-17T10:01:08.936732Z","shell.execute_reply.started":"2022-02-17T10:01:08.933244Z"},"trusted":true},"outputs":[],"source":["#previous_results_file = open(\"/kaggle/input/fasttextrepresentationsresults/FastTextExperimentsResults-baseline-lowercase.json\")\n","#previous_final_results = json.load(previous_results_file)\n","#len(previous_final_results)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-02-17T10:01:08.941135Z","iopub.status.busy":"2022-02-17T10:01:08.940402Z","iopub.status.idle":"2022-02-17T10:01:08.954833Z","shell.execute_reply":"2022-02-17T10:01:08.953851Z","shell.execute_reply.started":"2022-02-17T10:01:08.941077Z"},"trusted":true},"outputs":[],"source":["for element in final_results:\n","    previous_final_results.append(element)\n","\n","len(previous_final_results)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-02-17T10:01:08.957506Z","iopub.status.busy":"2022-02-17T10:01:08.956499Z","iopub.status.idle":"2022-02-17T10:01:08.970387Z","shell.execute_reply":"2022-02-17T10:01:08.969407Z","shell.execute_reply.started":"2022-02-17T10:01:08.957462Z"},"trusted":true},"outputs":[],"source":["def average_label_scores(representation):\n","    \"\"\"\n","    This function takes the label scores from the previous_final_results list for a chosen representation (value in \"experiment\")\n","    and returns a list containing a list of averages and a list of stds.\n","    \"\"\"\n","    average_label_score_baseline = {\"Info\":[], \"Promotion\":[], \"News\": [], \"Forum\": [], \"Opinion\": []}\n","\n","\n","    for element in previous_final_results:\n","        if element[\"experiment\"] == representation:\n","            average_label_score_baseline[\"Info\"].append(element[\"label_scores\"][\"__label__Information/Explanation\"])\n","            average_label_score_baseline[\"Promotion\"].append(element[\"label_scores\"][\"__label__Promotion\"])\n","            average_label_score_baseline[\"News\"].append(element[\"label_scores\"][\"__label__News\"])\n","            average_label_score_baseline[\"Forum\"].append(element[\"label_scores\"][\"__label__Forum\"])\n","            average_label_score_baseline[\"Opinion\"].append(element[\"label_scores\"][\"__label__Opinion/Argumentation\"])\n","\n","    baseline_list_of_averages = [np.array(average_label_score_baseline[\"Info\"]).mean(),np.array(average_label_score_baseline[\"Promotion\"]).mean(), np.array(average_label_score_baseline[\"News\"]).mean(), np.array(average_label_score_baseline[\"Forum\"]).mean(), np.array(average_label_score_baseline[\"Opinion\"]).mean()]\n","    baseline_list_of_stds = [np.array(average_label_score_baseline[\"Info\"]).std(),np.array(average_label_score_baseline[\"Promotion\"]).std(), np.array(average_label_score_baseline[\"News\"]).std(), np.array(average_label_score_baseline[\"Forum\"]).std(), np.array(average_label_score_baseline[\"Opinion\"]).std()]\n","\n","    return [baseline_list_of_averages, baseline_list_of_stds]"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-02-17T10:01:08.972177Z","iopub.status.busy":"2022-02-17T10:01:08.971779Z","iopub.status.idle":"2022-02-17T10:01:08.990376Z","shell.execute_reply":"2022-02-17T10:01:08.989161Z","shell.execute_reply.started":"2022-02-17T10:01:08.972131Z"},"trusted":true},"outputs":[],"source":["baseline_label_scores = average_label_scores(\"baseline_text\")\n","baseline_label_scores"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-02-17T10:01:08.992608Z","iopub.status.busy":"2022-02-17T10:01:08.992189Z","iopub.status.idle":"2022-02-17T10:01:09.00615Z","shell.execute_reply":"2022-02-17T10:01:09.005099Z","shell.execute_reply.started":"2022-02-17T10:01:08.992573Z"},"trusted":true},"outputs":[],"source":["current_representation_label_scores = average_label_scores(current_representation)\n","current_representation_label_scores"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-02-17T10:01:09.008232Z","iopub.status.busy":"2022-02-17T10:01:09.007956Z","iopub.status.idle":"2022-02-17T10:01:09.41589Z","shell.execute_reply":"2022-02-17T10:01:09.414972Z","shell.execute_reply.started":"2022-02-17T10:01:09.008201Z"},"trusted":true},"outputs":[],"source":["labels_names = ['Information/Explanation', 'Promotion', 'News', 'Forum', 'Opinion/Argumentation']\n","\n","fig, ax = plt.subplots(figsize=(4,4), dpi=200)\n","ax.errorbar(labels_names, baseline_label_scores[0], yerr=baseline_label_scores[1], label=\"baseline\", capsize=3)\n","ax.errorbar(labels_names, current_representation_label_scores[0], yerr=current_representation_label_scores[1], label=current_representation, capsize=3)\n","plt.xticks(fontsize=6)\n","ax.set_xlabel('Labels')\n","ax.set_ylabel('F1 Scores')\n","ax.legend(loc=\"lower right\")\n","#ax.set_xlabel(\"Impact of the Size of the Slovene Pre-Training Data on the Micro and Macro F1\")\n","plt.savefig(f\"baseline-versus-{current_representation}-label-scores.png\")\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-02-17T10:02:48.484157Z","iopub.status.busy":"2022-02-17T10:02:48.483817Z","iopub.status.idle":"2022-02-17T10:02:48.492787Z","shell.execute_reply":"2022-02-17T10:02:48.491947Z","shell.execute_reply.started":"2022-02-17T10:02:48.484125Z"},"trusted":true},"outputs":[],"source":["# Save the file with updated results.\n","with open(\"FastTextExperimentsResults-all-current-representations-updated.json\", \"w\") as results_file:\n","    json.dump(previous_final_results,results_file, indent= \"\")"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.4"}},"nbformat":4,"nbformat_minor":4}
