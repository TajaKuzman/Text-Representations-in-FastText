{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Learning on various text representations - shortened","metadata":{}},{"cell_type":"markdown","source":"This notebook was used to ran all of the experiments, based on the functions, defined in the utility scripts at the beginning of the file. To inspect step-by-step procedure, see the *3-Learning-On-Various_Representations.ipynb* file.","metadata":{}},{"cell_type":"markdown","source":"## Preparing the dataset for FastText","metadata":{}},{"cell_type":"markdown","source":"Importing the necessary libraries","metadata":{}},{"cell_type":"code","source":"!pip install parse","metadata":{"execution":{"iopub.status.busy":"2022-02-17T07:53:05.881471Z","iopub.execute_input":"2022-02-17T07:53:05.882134Z","iopub.status.idle":"2022-02-17T07:53:19.534355Z","shell.execute_reply.started":"2022-02-17T07:53:05.882037Z","shell.execute_reply":"2022-02-17T07:53:19.533351Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import json\nimport pandas as pd\nfrom copy import deepcopy\nimport re\nfrom tqdm import tqdm\nimport fasttext as ft\nimport parse\nimport numpy as np\nfrom sklearn.metrics import f1_score\nfrom sklearn.metrics import confusion_matrix\nimport matplotlib.pyplot as plt","metadata":{"execution":{"iopub.status.busy":"2022-02-17T07:53:19.536312Z","iopub.execute_input":"2022-02-17T07:53:19.536555Z","iopub.status.idle":"2022-02-17T07:53:20.659237Z","shell.execute_reply.started":"2022-02-17T07:53:19.536526Z","shell.execute_reply":"2022-02-17T07:53:20.658387Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Add all utility scripts:","metadata":{}},{"cell_type":"code","source":"# Creating FastText train and test files\n\n\ndef fastText_files(representation):\n    \"\"\"\n    This function creates and saves the test and train file\n    from the test, train and dev split of the dataset (named test, dev and train),\n    using the \"primary_level_3\" level labels, and the chosen text representation.\n    \n    Possible representations: 'baseline_text', 'lemmas',\n    'upos', 'xpos', 'ner', 'dependency', 'lowercase', 'lowercase_nopunctuation'\n    \n    The function returns a list of the following elements:\n        - labels - which can be used for prediction and evaluation.\n        - train file path\n        - test file path\n    \n    Args:\n        representation (str): the name of the key (from the dataset)\n                                of the text representation we want to use\n    \"\"\"\n    # First create the dataframes from each split:\n    \n    train_df = pd.DataFrame(data=train, columns=[representation, \"primary_level_3\"])\n    # Renaming columns to `text` and `labels`\n    train_df.columns = [\"text\", \"labels\"]\n    \n    test_df = pd.DataFrame(data=test, columns=[representation, \"primary_level_3\"])\n    test_df.columns = [\"text\", \"labels\"]\n    \n    print(\"The shape of the dataframes:\")\n    print(train_df.shape, test_df.shape)\n    \n    # Then create CSV files which FastText can read\n    \n    train_file_content=\"\"\n\n    for labels, text in train_df.loc[:, [\"labels\", \"text\"]].values:\n        label = f\"__label__{labels}\"\n        train_file_content += f\"\"\"{label} {text}\\n\"\"\"\n    \n    train_path = \"\"\n    train_path = representation + \"-fasttext.train\"\n\n    with open(train_path,\"w\") as train_file:\n        train_file.write(train_file_content)\n    \n    train_example = open(train_path,\"r\").read(1000)\n    print(\"Created train file:\")\n    print(train_example)\n    \n    test_file_content=\"\"\n    \n    for labels, text in test_df.loc[:, [\"labels\", \"text\"]].values:\n        label = f\"__label__{labels}\"\n        test_file_content += f\"\"\"{label} {text}\\n\"\"\"\n    \n    test_path = \"\"\n    test_path = representation + \"-fasttext.test\"\n    \n    with open(test_path,\"w\") as test_file:\n        test_file.write(test_file_content)\n    \n    test_example = open(test_path,\"r\").read(1000)\n    print(\"Created test file:\")\n    print(test_example)\n    \n    \n    # Finally, create a list of labels which can be used for prediction and evaluation.\n    # Let's inspect the labels:\n    all_df_labels = train_df[\"labels\"].unique().tolist()\n    \n    for i in test_df[\"labels\"].unique().tolist():\n        if i not in all_df_labels:\n            all_df_labels.append(i)\n\n    print(f\"Number of all labels: {len(all_df_labels)}\")\n    \n    # Create a final list of labels in a FastText-appropriate format:\n    LABELS = train_df.labels.unique().tolist()\n    LABELS = [f\"__label__{i}\" for i in LABELS]\n    \n    return_list = [LABELS, train_path, test_path]\n    print(f\"The function returned the following list: {return_list}\")\n    \n    return return_list\n\n# Parsing test file\ndef parse_test_file(path: str):\n    \"\"\"Reads fasttext formatted file and returns labels, texts.\"\"\"\n    with open(path, \"r\") as f:\n        content = f.readlines()\n    pattern = \"{label} {text}\\n\"\n    p = parse.compile(pattern)\n\n    labels, texts = list(), list()\n    for line in content:\n        rez = p.parse(line)\n        if rez is not None:\n            labels.append(rez[\"label\"])\n            texts.append(rez[\"text\"])\n        else:\n            print(\"error parsing line \", line)\n    return labels, texts\n\ndef prediction_to_label(prediction):\n    \"\"\"Transforms predictions as returned by fasttext into pure labels.\"\"\"\n    return np.array(prediction[0])[:, 0]\n\ndef train_FastText(representation):\n    \"\"\"\n    The function uses the created FT_train_file and FT_test_file\n    and performs five runs of training and evaluation of the model.\n    It plots a confusion matrix for each run.\n\n    Args:\n        representation (str): the name of the key (from the dataset)\n                                of the text representation we want to use\n    \n    \"\"\"\n    results = []\n\n    for i in range(5):\n        model = ft.train_supervised(input=FT_train_file,\n                                    epoch = 350,\n                                    lr = 0.7,\n                                    wordNgrams=1,\n                                    verbose = 2\n                                                )\n        # Parse the test files so that labels and texts are separated\n        y_true, y_texts = parse_test_file(FT_test_file)\n\n        # Evaluate the model on test data\n        y_pred = model.predict(y_texts)\n        y_pred = prediction_to_label(y_pred)\n\n        # Plot the confusion matrix:\n        cm = confusion_matrix(y_true, y_pred, labels=LABELS)\n        plt.figure(figsize=(9, 9))\n        plt.imshow(cm, cmap=\"Oranges\")\n        classNames = LABELS\n        plt.ylabel('True label')\n        plt.xlabel('Predicted label')\n        tick_marks = np.arange(len(classNames))\n        plt.xticks(tick_marks, classNames, rotation=90)\n        plt.yticks(tick_marks, classNames)\n        \n        m = f1_score(y_true, y_pred, labels=LABELS, average =\"micro\")\n        M = f1_score(y_true, y_pred, labels=LABELS, average =\"macro\")\n        score_per_label = list(f1_score(y_true, y_pred, labels=LABELS, average=None))\n        \n        dict_score_per_label = {}\n        \n        for index in range(len(LABELS)):\n            dict_score_per_label[LABELS[index]] = score_per_label[index]\n             \n        print(f\"Score per labels: {dict_score_per_label}\")\n\n        metrics = f\"{m:0.4}, {M:0.4}\"\n        title = f\"Representation: {representation}, Run: {i}\"\n        plt.title(title +\";\\n\" + metrics)\n        plt.tight_layout()\n        plt.savefig(title)\n        plt.show()\n        \n        rezdict = {}\n        \n        rezdict = {\n            \"microF1\": m,\n            \"macroF1\": M,\n            \"label_scores\": dict_score_per_label,\n            \"run\": i,\n            \"experiment\": representation,\n        }\n        results.append(rezdict)\n        final_results.append(rezdict)\n    \n    # Calculate the average micro and macro F1 for the 5 runs:\n    mi = []\n    ma = []\n    \n    for i in results:\n        mi.append(i['microF1'])\n        ma.append(i[\"macroF1\"])\n\n    print(f\"micro F1: {np.array(mi).mean():0.03} +/- {np.array(mi).std():0.02}\")\n    print(f\"macro F1: {np.array(ma).mean():0.03} +/- {np.array(ma).std():0.02}\")\n    ","metadata":{"execution":{"iopub.status.busy":"2022-02-17T07:53:20.661092Z","iopub.execute_input":"2022-02-17T07:53:20.661467Z","iopub.status.idle":"2022-02-17T07:53:20.694859Z","shell.execute_reply.started":"2022-02-17T07:53:20.661429Z","shell.execute_reply":"2022-02-17T07:53:20.693883Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Import the file with additional text representations (only the paragraphs marked to be kept\n# in the original corpus are included)\n\nwith open(\"/kaggle/input/ginco-with-additional-text-representations/Language-Processed-GINCO.json\") as f:\n    dataset = json.load(f)","metadata":{"executionInfo":{"elapsed":389,"status":"ok","timestamp":1640949108560,"user":{"displayName":"Taja Kuzman","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16199926972677634189"},"user_tz":-60},"id":"qL9iYqif_lSk","execution":{"iopub.status.busy":"2022-02-17T07:53:20.697088Z","iopub.execute_input":"2022-02-17T07:53:20.697356Z","iopub.status.idle":"2022-02-17T07:53:22.260451Z","shell.execute_reply.started":"2022-02-17T07:53:20.697315Z","shell.execute_reply":"2022-02-17T07:53:22.259406Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset[0].keys()","metadata":{"execution":{"iopub.status.busy":"2022-02-17T07:53:22.261892Z","iopub.execute_input":"2022-02-17T07:53:22.262745Z","iopub.status.idle":"2022-02-17T07:53:22.273488Z","shell.execute_reply.started":"2022-02-17T07:53:22.262699Z","shell.execute_reply":"2022-02-17T07:53:22.272611Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Pre-processing dataset","metadata":{}},{"cell_type":"markdown","source":"Here we can create additional representations if we wish (see the notebook *2-Language-Processing-of-GINCO*).","metadata":{}},{"cell_type":"markdown","source":"1. Remove punctuation from each token","metadata":{}},{"cell_type":"code","source":"from string import punctuation\n\nfor instance in tqdm(dataset):\n        text = instance[\"baseline_text\"]\n        \n        # split text into tokens by white space\n        token = text.split()\n         \n        # remove punctuation from each token\n        table = str.maketrans('', '', punctuation)\n        token = [word.translate(table) for word in token]\n\n        # add a new key with punctuation removed\n        instance[\"nopunctuation\"] = \" \".join(token)","metadata":{"execution":{"iopub.status.busy":"2022-02-17T07:53:22.275028Z","iopub.execute_input":"2022-02-17T07:53:22.275338Z","iopub.status.idle":"2022-02-17T07:53:22.575153Z","shell.execute_reply.started":"2022-02-17T07:53:22.275288Z","shell.execute_reply":"2022-02-17T07:53:22.574358Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset[0]","metadata":{"execution":{"iopub.status.busy":"2022-02-17T07:53:22.576376Z","iopub.execute_input":"2022-02-17T07:53:22.576596Z","iopub.status.idle":"2022-02-17T07:53:22.596389Z","shell.execute_reply.started":"2022-02-17T07:53:22.57657Z","shell.execute_reply":"2022-02-17T07:53:22.595358Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"2. Remove numbers from each token","metadata":{}},{"cell_type":"code","source":"from string import digits\n\nfor instance in tqdm(dataset):\n        text = instance[\"baseline_text\"]\n\n        # remove digits from each token\n        remove_digits = str.maketrans('', '', digits)\n        text_no_digits = text.translate(remove_digits)\n\n        # add a new key with digits removed\n        instance[\"nonumbers\"] = text_no_digits\n        \ndataset[-1]","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2022-02-17T09:01:13.016257Z","iopub.execute_input":"2022-02-17T09:01:13.016558Z","iopub.status.idle":"2022-02-17T09:01:13.264211Z","shell.execute_reply.started":"2022-02-17T09:01:13.016525Z","shell.execute_reply":"2022-02-17T09:01:13.263343Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"4. Apply all (lowercase, remove punctuation, numbers)","metadata":{}},{"cell_type":"code","source":"# Let's apply punctuation and number removal on the lowercase text.\n\nfor instance in tqdm(dataset):\n        text = instance['lowercase']\n        \n        # split text into tokens by white space\n        token = text.split()\n         \n        # remove punctuation from each token\n        table = str.maketrans('', '', punctuation)\n        token = [word.translate(table) for word in token]\n\n        text_no_punctuation = \" \".join(token)\n        \n        # remove digits from each token\n        remove_digits = str.maketrans('', '', digits)\n        text_no_digits = text_no_punctuation.translate(remove_digits)\n\n        # add a new key with lowercase text with punctuation and digits removed\n        instance[\"lowercase_nopunct_nodigits\"] = text_no_digits\n\ndataset[-1]","metadata":{"execution":{"iopub.status.busy":"2022-02-17T09:32:54.435808Z","iopub.execute_input":"2022-02-17T09:32:54.436692Z","iopub.status.idle":"2022-02-17T09:32:54.978938Z","shell.execute_reply.started":"2022-02-17T09:32:54.43665Z","shell.execute_reply":"2022-02-17T09:32:54.977865Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Downcasting number of labels","metadata":{}},{"cell_type":"markdown","source":"In these experiments, we will not use all of the texts but only texts from 5 main categories, meaning that some categories will be merged into them, whereas some categories with a very small frequency will be discarded. Additionally, the texts marked us hard, will be discarded (see notebook *1-Preparing_Data_Hyperparameter_Search*).\n\nWe will start with a reduced set of labels (primary_level_3), then merge News and Opinionated News, and discard some of the lables.","metadata":{}},{"cell_type":"code","source":"# merge News and Opinionated News\nfor i in dataset:\n    if i[\"primary_level_3\"] == \"Opinionated News\" or i[\"primary_level_3\"] == \"News/Reporting\":\n        i[\"primary_level_3\"] = \"News\"","metadata":{"execution":{"iopub.status.busy":"2022-02-17T09:33:22.888953Z","iopub.execute_input":"2022-02-17T09:33:22.889569Z","iopub.status.idle":"2022-02-17T09:33:22.897759Z","shell.execute_reply.started":"2022-02-17T09:33:22.889511Z","shell.execute_reply":"2022-02-17T09:33:22.896454Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let's create train:test:dev split that contains only the wanted labels.","metadata":{}},{"cell_type":"code","source":"downcasted_labels = ['Information/Explanation', 'Promotion', 'News', 'Forum', 'Opinion/Argumentation']\n\ntrain = [i for i in dataset if i[\"split\"] == \"train\" and i[\"primary_level_3\"] in downcasted_labels and not i[\"hard\"]]\ntest = [i for i in dataset if i[\"split\"] == \"test\" and i[\"primary_level_3\"] in downcasted_labels and not i[\"hard\"]]\ndev = [i for i in dataset if i[\"split\"] == \"dev\" and i[\"primary_level_3\"] in downcasted_labels and not i[\"hard\"]]\n\nprint(\"The train-dev-test splits consist of the following numbers of examples:\", len(train), len(test), len(dev))","metadata":{"execution":{"iopub.status.busy":"2022-02-17T09:33:22.901002Z","iopub.execute_input":"2022-02-17T09:33:22.901782Z","iopub.status.idle":"2022-02-17T09:33:22.918049Z","shell.execute_reply.started":"2022-02-17T09:33:22.901711Z","shell.execute_reply":"2022-02-17T09:33:22.916886Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f\"Number of all texts is {len(train)+len(test)+len(dev)}\")","metadata":{"execution":{"iopub.status.busy":"2022-02-17T09:33:22.919344Z","iopub.execute_input":"2022-02-17T09:33:22.920073Z","iopub.status.idle":"2022-02-17T09:33:22.932585Z","shell.execute_reply.started":"2022-02-17T09:33:22.920032Z","shell.execute_reply":"2022-02-17T09:33:22.931452Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Creating FastText texts","metadata":{}},{"cell_type":"markdown","source":"Use the function fastText_files(representation) from the utility functions.\n\nThis function creates and saves the test and train file\n    from the test, train and dev split of the dataset (named test, dev and train),\n    using the \"primary_level_3\" level labels, and the chosen text representation.","metadata":{"id":"xw1ugH8i6KuD"}},{"cell_type":"code","source":"dataset[0].keys()","metadata":{"execution":{"iopub.status.busy":"2022-02-17T09:33:58.729347Z","iopub.execute_input":"2022-02-17T09:33:58.729787Z","iopub.status.idle":"2022-02-17T09:33:58.735705Z","shell.execute_reply.started":"2022-02-17T09:33:58.729748Z","shell.execute_reply":"2022-02-17T09:33:58.734804Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"current_representation = 'ner'","metadata":{"execution":{"iopub.status.busy":"2022-02-17T09:59:18.877623Z","iopub.execute_input":"2022-02-17T09:59:18.878014Z","iopub.status.idle":"2022-02-17T09:59:18.883599Z","shell.execute_reply.started":"2022-02-17T09:59:18.877973Z","shell.execute_reply":"2022-02-17T09:59:18.882336Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"final_results = list()","metadata":{"execution":{"iopub.status.busy":"2022-02-17T09:59:20.77553Z","iopub.execute_input":"2022-02-17T09:59:20.775877Z","iopub.status.idle":"2022-02-17T09:59:20.780297Z","shell.execute_reply.started":"2022-02-17T09:59:20.77584Z","shell.execute_reply":"2022-02-17T09:59:20.779275Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"representation = fastText_files(current_representation)","metadata":{"execution":{"iopub.status.busy":"2022-02-17T09:59:23.359384Z","iopub.execute_input":"2022-02-17T09:59:23.359928Z","iopub.status.idle":"2022-02-17T09:59:23.382687Z","shell.execute_reply.started":"2022-02-17T09:59:23.359855Z","shell.execute_reply":"2022-02-17T09:59:23.381654Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Train a fastText model","metadata":{"id":"QB0_-1xIRPx-"}},{"cell_type":"code","source":"# Define the label list:\nLABELS = representation[0]\n\nLABELS","metadata":{"execution":{"iopub.status.busy":"2022-02-17T09:59:31.653618Z","iopub.execute_input":"2022-02-17T09:59:31.653954Z","iopub.status.idle":"2022-02-17T09:59:31.660242Z","shell.execute_reply.started":"2022-02-17T09:59:31.653894Z","shell.execute_reply":"2022-02-17T09:59:31.659417Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Input the data:","metadata":{}},{"cell_type":"code","source":"FT_train_file = representation[1]\nFT_test_file = representation[2]","metadata":{"id":"s3ytA4GWVVhk","execution":{"iopub.status.busy":"2022-02-17T09:59:31.661733Z","iopub.execute_input":"2022-02-17T09:59:31.662476Z","iopub.status.idle":"2022-02-17T09:59:31.672159Z","shell.execute_reply.started":"2022-02-17T09:59:31.662432Z","shell.execute_reply":"2022-02-17T09:59:31.671216Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Use the train_FastText(representation) function from utils.py","metadata":{}},{"cell_type":"code","source":"train_FastText(current_representation)","metadata":{"execution":{"iopub.status.busy":"2022-02-17T09:59:31.673247Z","iopub.execute_input":"2022-02-17T09:59:31.673841Z","iopub.status.idle":"2022-02-17T10:00:07.313125Z","shell.execute_reply.started":"2022-02-17T09:59:31.673806Z","shell.execute_reply":"2022-02-17T10:00:07.31211Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(final_results)","metadata":{"execution":{"iopub.status.busy":"2022-02-17T10:00:07.314693Z","iopub.execute_input":"2022-02-17T10:00:07.315078Z","iopub.status.idle":"2022-02-17T10:00:07.322078Z","shell.execute_reply.started":"2022-02-17T10:00:07.315029Z","shell.execute_reply":"2022-02-17T10:00:07.320981Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(final_results[0])\nprint(final_results[-1])","metadata":{"execution":{"iopub.status.busy":"2022-02-17T10:00:07.324463Z","iopub.execute_input":"2022-02-17T10:00:07.32527Z","iopub.status.idle":"2022-02-17T10:00:07.336861Z","shell.execute_reply.started":"2022-02-17T10:00:07.325224Z","shell.execute_reply":"2022-02-17T10:00:07.335956Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"stop = ","metadata":{"execution":{"iopub.status.busy":"2022-02-17T10:00:07.337976Z","iopub.execute_input":"2022-02-17T10:00:07.338467Z","iopub.status.idle":"2022-02-17T10:00:07.352696Z","shell.execute_reply.started":"2022-02-17T10:00:07.338433Z","shell.execute_reply":"2022-02-17T10:00:07.3513Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#previous_results_file = open(\"/kaggle/input/fasttextrepresentationsresults/FastTextExperimentsResults-baseline-lowercase.json\")\n#previous_final_results = json.load(previous_results_file)\n#len(previous_final_results)","metadata":{"execution":{"iopub.status.busy":"2022-02-17T10:01:08.932957Z","iopub.execute_input":"2022-02-17T10:01:08.933294Z","iopub.status.idle":"2022-02-17T10:01:08.937888Z","shell.execute_reply.started":"2022-02-17T10:01:08.933244Z","shell.execute_reply":"2022-02-17T10:01:08.936732Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for element in final_results:\n    previous_final_results.append(element)\n\nlen(previous_final_results)","metadata":{"execution":{"iopub.status.busy":"2022-02-17T10:01:08.940402Z","iopub.execute_input":"2022-02-17T10:01:08.941135Z","iopub.status.idle":"2022-02-17T10:01:08.954833Z","shell.execute_reply.started":"2022-02-17T10:01:08.941077Z","shell.execute_reply":"2022-02-17T10:01:08.953851Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def average_label_scores(representation):\n    \"\"\"\n    This function takes the label scores from the previous_final_results list for a chosen representation (value in \"experiment\")\n    and returns a list containing a list of averages and a list of stds.\n    \"\"\"\n    average_label_score_baseline = {\"Info\":[], \"Promotion\":[], \"News\": [], \"Forum\": [], \"Opinion\": []}\n\n\n    for element in previous_final_results:\n        if element[\"experiment\"] == representation:\n            average_label_score_baseline[\"Info\"].append(element[\"label_scores\"][\"__label__Information/Explanation\"])\n            average_label_score_baseline[\"Promotion\"].append(element[\"label_scores\"][\"__label__Promotion\"])\n            average_label_score_baseline[\"News\"].append(element[\"label_scores\"][\"__label__News\"])\n            average_label_score_baseline[\"Forum\"].append(element[\"label_scores\"][\"__label__Forum\"])\n            average_label_score_baseline[\"Opinion\"].append(element[\"label_scores\"][\"__label__Opinion/Argumentation\"])\n\n    baseline_list_of_averages = [np.array(average_label_score_baseline[\"Info\"]).mean(),np.array(average_label_score_baseline[\"Promotion\"]).mean(), np.array(average_label_score_baseline[\"News\"]).mean(), np.array(average_label_score_baseline[\"Forum\"]).mean(), np.array(average_label_score_baseline[\"Opinion\"]).mean()]\n    baseline_list_of_stds = [np.array(average_label_score_baseline[\"Info\"]).std(),np.array(average_label_score_baseline[\"Promotion\"]).std(), np.array(average_label_score_baseline[\"News\"]).std(), np.array(average_label_score_baseline[\"Forum\"]).std(), np.array(average_label_score_baseline[\"Opinion\"]).std()]\n\n    return [baseline_list_of_averages, baseline_list_of_stds]","metadata":{"execution":{"iopub.status.busy":"2022-02-17T10:01:08.956499Z","iopub.execute_input":"2022-02-17T10:01:08.957506Z","iopub.status.idle":"2022-02-17T10:01:08.970387Z","shell.execute_reply.started":"2022-02-17T10:01:08.957462Z","shell.execute_reply":"2022-02-17T10:01:08.969407Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"baseline_label_scores = average_label_scores(\"baseline_text\")\nbaseline_label_scores","metadata":{"execution":{"iopub.status.busy":"2022-02-17T10:01:08.971779Z","iopub.execute_input":"2022-02-17T10:01:08.972177Z","iopub.status.idle":"2022-02-17T10:01:08.990376Z","shell.execute_reply.started":"2022-02-17T10:01:08.972131Z","shell.execute_reply":"2022-02-17T10:01:08.989161Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"current_representation_label_scores = average_label_scores(current_representation)\ncurrent_representation_label_scores","metadata":{"execution":{"iopub.status.busy":"2022-02-17T10:01:08.992189Z","iopub.execute_input":"2022-02-17T10:01:08.992608Z","iopub.status.idle":"2022-02-17T10:01:09.00615Z","shell.execute_reply.started":"2022-02-17T10:01:08.992573Z","shell.execute_reply":"2022-02-17T10:01:09.005099Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"labels_names = ['Information/Explanation', 'Promotion', 'News', 'Forum', 'Opinion/Argumentation']\n\nfig, ax = plt.subplots(figsize=(4,4), dpi=200)\nax.errorbar(labels_names, baseline_label_scores[0], yerr=baseline_label_scores[1], label=\"baseline\", capsize=3)\nax.errorbar(labels_names, current_representation_label_scores[0], yerr=current_representation_label_scores[1], label=current_representation, capsize=3)\nplt.xticks(fontsize=6)\nax.set_xlabel('Labels')\nax.set_ylabel('F1 Scores')\nax.legend(loc=\"lower right\")\n#ax.set_xlabel(\"Impact of the Size of the Slovene Pre-Training Data on the Micro and Macro F1\")\nplt.savefig(f\"baseline-versus-{current_representation}-label-scores.png\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-02-17T10:01:09.007956Z","iopub.execute_input":"2022-02-17T10:01:09.008232Z","iopub.status.idle":"2022-02-17T10:01:09.41589Z","shell.execute_reply.started":"2022-02-17T10:01:09.008201Z","shell.execute_reply":"2022-02-17T10:01:09.414972Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"stop = ","metadata":{"execution":{"iopub.status.busy":"2022-02-17T10:01:09.417165Z","iopub.execute_input":"2022-02-17T10:01:09.417416Z","iopub.status.idle":"2022-02-17T10:01:09.423511Z","shell.execute_reply.started":"2022-02-17T10:01:09.417376Z","shell.execute_reply":"2022-02-17T10:01:09.422212Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Save the file with updated results.\nwith open(\"FastTextExperimentsResults-all-current-representations-updated.json\", \"w\") as results_file:\n    json.dump(previous_final_results,results_file, indent= \"\")","metadata":{"execution":{"iopub.status.busy":"2022-02-17T10:02:48.483817Z","iopub.execute_input":"2022-02-17T10:02:48.484157Z","iopub.status.idle":"2022-02-17T10:02:48.492787Z","shell.execute_reply.started":"2022-02-17T10:02:48.484125Z","shell.execute_reply":"2022-02-17T10:02:48.491947Z"},"trusted":true},"execution_count":null,"outputs":[]}]}