{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Training a Transformer model"]},{"cell_type":"markdown","metadata":{},"source":["To compare the fastText performance with the performance of Transformer models, I also trained the base-sized XLM-RoBERTa model on the baseline text."]},{"cell_type":"markdown","metadata":{},"source":["## Training and testing on Transformer models"]},{"cell_type":"markdown","metadata":{},"source":["Importing the necessary libraries"]},{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2022-08-18T06:48:59.552479Z","iopub.status.busy":"2022-08-18T06:48:59.551683Z","iopub.status.idle":"2022-08-18T06:49:03.862256Z","shell.execute_reply":"2022-08-18T06:49:03.860903Z","shell.execute_reply.started":"2022-08-18T06:48:59.552357Z"},"trusted":true},"outputs":[],"source":["# install the libraries necessary for data wrangling, prediction and result analysis\n","import json\n","import numpy as np\n","import pandas as pd\n","import logging\n","import matplotlib.pyplot as plt\n","from sklearn import metrics\n","from sklearn.metrics import classification_report, confusion_matrix, f1_score,precision_score, recall_score\n","import torch\n","from numba import cuda\n","from sklearn.model_selection import train_test_split\n","from sklearn.dummy import DummyClassifier"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2022-08-18T06:49:17.848290Z","iopub.status.busy":"2022-08-18T06:49:17.847941Z","iopub.status.idle":"2022-08-18T06:49:30.005084Z","shell.execute_reply":"2022-08-18T06:49:30.003767Z","shell.execute_reply.started":"2022-08-18T06:49:17.848258Z"},"trusted":true},"outputs":[],"source":["# Install transformers\n","# (this needs to be done on Kaggle each time you start the session)\n","!pip install -q transformers"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2022-08-18T06:49:30.009867Z","iopub.status.busy":"2022-08-18T06:49:30.008811Z","iopub.status.idle":"2022-08-18T06:50:03.801600Z","shell.execute_reply":"2022-08-18T06:50:03.800303Z","shell.execute_reply.started":"2022-08-18T06:49:30.009812Z"},"trusted":true},"outputs":[],"source":["# Install the simpletransformers\n","!pip install -q simpletransformers\n","from simpletransformers.classification import ClassificationModel"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2022-08-18T06:50:03.804371Z","iopub.status.busy":"2022-08-18T06:50:03.803962Z","iopub.status.idle":"2022-08-18T06:50:23.151602Z","shell.execute_reply":"2022-08-18T06:50:23.150363Z","shell.execute_reply.started":"2022-08-18T06:50:03.804324Z"},"trusted":true},"outputs":[],"source":["# Install wandb\n","!pip install -q wandb\n","import wandb\n","# Login to wandb\n","wandb.login()"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2022-08-18T06:50:23.155804Z","iopub.status.busy":"2022-08-18T06:50:23.155482Z","iopub.status.idle":"2022-08-18T06:50:24.913657Z","shell.execute_reply":"2022-08-18T06:50:24.912500Z","shell.execute_reply.started":"2022-08-18T06:50:23.155771Z"},"trusted":true},"outputs":[],"source":["#Import the data\n","dataframe = pd.read_json(\"/kaggle/input/ginco-with-additional-text-representations/Language-Processed-GINCO.json\")\n"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2022-08-18T06:50:24.916258Z","iopub.status.busy":"2022-08-18T06:50:24.915285Z","iopub.status.idle":"2022-08-18T06:50:25.002871Z","shell.execute_reply":"2022-08-18T06:50:25.001790Z","shell.execute_reply.started":"2022-08-18T06:50:24.916211Z"},"trusted":true},"outputs":[],"source":["dataframe.head(2)"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2022-08-18T06:50:25.004932Z","iopub.status.busy":"2022-08-18T06:50:25.004201Z","iopub.status.idle":"2022-08-18T06:50:25.013324Z","shell.execute_reply":"2022-08-18T06:50:25.011935Z","shell.execute_reply.started":"2022-08-18T06:50:25.004888Z"},"trusted":true},"outputs":[],"source":["dataframe.shape"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2022-08-18T06:50:25.016784Z","iopub.status.busy":"2022-08-18T06:50:25.015342Z","iopub.status.idle":"2022-08-18T06:50:25.027395Z","shell.execute_reply":"2022-08-18T06:50:25.026222Z","shell.execute_reply.started":"2022-08-18T06:50:25.016706Z"},"trusted":true},"outputs":[],"source":["# Add the downcasted labels\n","dataframe[\"downcasted_to_5\"] = np.where((dataframe['primary_level_3'] == 'Opinionated News'),'News', dataframe['primary_level_3'])\n","\n","dataframe[\"downcasted_to_5\"] = np.where((dataframe['downcasted_to_5'] == 'News/Reporting'),'News', dataframe['downcasted_to_5'])"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2022-08-18T06:50:25.030159Z","iopub.status.busy":"2022-08-18T06:50:25.029853Z","iopub.status.idle":"2022-08-18T06:50:25.043162Z","shell.execute_reply":"2022-08-18T06:50:25.041689Z","shell.execute_reply.started":"2022-08-18T06:50:25.030101Z"},"trusted":true},"outputs":[],"source":["dataframe[\"downcasted_to_5\"].unique()"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2022-08-18T06:50:25.045805Z","iopub.status.busy":"2022-08-18T06:50:25.045462Z","iopub.status.idle":"2022-08-18T06:50:25.125335Z","shell.execute_reply":"2022-08-18T06:50:25.124067Z","shell.execute_reply.started":"2022-08-18T06:50:25.045761Z"},"trusted":true},"outputs":[],"source":["dataframe.head(2)"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2022-08-18T06:50:25.130165Z","iopub.status.busy":"2022-08-18T06:50:25.129759Z","iopub.status.idle":"2022-08-18T06:50:25.283426Z","shell.execute_reply":"2022-08-18T06:50:25.282045Z","shell.execute_reply.started":"2022-08-18T06:50:25.130120Z"},"trusted":true},"outputs":[],"source":["# Discard texts with labels that are not in the reduced set\n","# and create train-test-dev splits\n","downcasted_labels = ['Information/Explanation', 'Promotion', 'News', 'Forum', 'Opinion/Argumentation']\n","\n","dataframe = dataframe[dataframe[\"downcasted_to_5\"].isin(downcasted_labels)]\n","\n","dataframe.describe(include=\"all\")"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2022-08-18T06:50:25.285796Z","iopub.status.busy":"2022-08-18T06:50:25.285367Z","iopub.status.idle":"2022-08-18T06:50:25.296769Z","shell.execute_reply":"2022-08-18T06:50:25.295514Z","shell.execute_reply.started":"2022-08-18T06:50:25.285720Z"},"trusted":true},"outputs":[],"source":["dataframe.hard.value_counts()"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2022-08-18T06:50:25.299715Z","iopub.status.busy":"2022-08-18T06:50:25.298474Z","iopub.status.idle":"2022-08-18T06:50:25.434146Z","shell.execute_reply":"2022-08-18T06:50:25.432962Z","shell.execute_reply.started":"2022-08-18T06:50:25.299684Z"},"trusted":true},"outputs":[],"source":["# Discard hard texts\n","dataframe = dataframe[dataframe[\"hard\"] != True]\n","dataframe.describe(include=\"all\")"]},{"cell_type":"code","execution_count":20,"metadata":{"execution":{"iopub.execute_input":"2022-08-18T06:51:18.927608Z","iopub.status.busy":"2022-08-18T06:51:18.927191Z","iopub.status.idle":"2022-08-18T06:51:18.941002Z","shell.execute_reply":"2022-08-18T06:51:18.939887Z","shell.execute_reply.started":"2022-08-18T06:51:18.927574Z"},"trusted":true},"outputs":[],"source":["# Split the dataset into train, test and dev split\n","first_train_df = dataframe[dataframe[\"split\"] == \"train\"]\n","first_test_df = dataframe[dataframe[\"split\"] == \"test\"]\n","first_dev_df = dataframe[dataframe[\"split\"] == \"dev\"]\n","\n","print(f\"The train-dev-test splits consist of the following numbers of examples: {first_train_df.shape}, {first_dev_df.shape}, {first_test_df.shape}\")"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2022-08-18T06:50:25.452005Z","iopub.status.busy":"2022-08-18T06:50:25.450955Z","iopub.status.idle":"2022-08-18T06:50:25.468873Z","shell.execute_reply":"2022-08-18T06:50:25.467543Z","shell.execute_reply.started":"2022-08-18T06:50:25.451900Z"},"trusted":true},"outputs":[],"source":["# Create a proper train df dataframe\n","train_df = pd.DataFrame({\"text\": first_train_df[\"baseline_text\"], \"labels\": first_train_df[\"downcasted_to_5\"]})\n","\n","train_df.head(2)"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2022-08-18T06:50:25.471645Z","iopub.status.busy":"2022-08-18T06:50:25.471267Z","iopub.status.idle":"2022-08-18T06:50:25.487919Z","shell.execute_reply":"2022-08-18T06:50:25.486420Z","shell.execute_reply.started":"2022-08-18T06:50:25.471605Z"},"trusted":true},"outputs":[],"source":["# Create a proper test df dataframe\n","test_df = pd.DataFrame({\"text\": first_test_df[\"baseline_text\"], \"labels\": first_test_df[\"downcasted_to_5\"]})\n","\n","test_df.head(2)"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2022-08-18T06:50:25.490153Z","iopub.status.busy":"2022-08-18T06:50:25.489603Z","iopub.status.idle":"2022-08-18T06:50:25.506906Z","shell.execute_reply":"2022-08-18T06:50:25.505673Z","shell.execute_reply.started":"2022-08-18T06:50:25.490110Z"},"trusted":true},"outputs":[],"source":["# Create a proper dev df dataframe\n","dev_df = pd.DataFrame({\"text\": first_dev_df[\"baseline_text\"], \"labels\": first_dev_df[\"downcasted_to_5\"]})\n","\n","dev_df.head(2)"]},{"cell_type":"code","execution_count":18,"metadata":{"execution":{"iopub.execute_input":"2022-08-18T06:50:25.510336Z","iopub.status.busy":"2022-08-18T06:50:25.509686Z","iopub.status.idle":"2022-08-18T06:50:25.519834Z","shell.execute_reply":"2022-08-18T06:50:25.518417Z","shell.execute_reply.started":"2022-08-18T06:50:25.510292Z"},"trusted":true},"outputs":[],"source":["LABELS = list(train_df[\"labels\"].unique())\n","LABELS"]},{"cell_type":"code","execution_count":19,"metadata":{"execution":{"iopub.execute_input":"2022-08-18T06:50:25.522378Z","iopub.status.busy":"2022-08-18T06:50:25.521814Z","iopub.status.idle":"2022-08-18T06:50:25.528685Z","shell.execute_reply":"2022-08-18T06:50:25.526881Z","shell.execute_reply.started":"2022-08-18T06:50:25.522334Z"},"trusted":true},"outputs":[],"source":["#We will use the multilingual XLM-RoBERTa model\n","#https://huggingface.co/xlm-roberta-base\n","import os\n","os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-08-16T12:50:25.163713Z","iopub.status.busy":"2022-08-16T12:50:25.163437Z","iopub.status.idle":"2022-08-16T12:50:36.041416Z","shell.execute_reply":"2022-08-16T12:50:36.040360Z","shell.execute_reply.started":"2022-08-16T12:50:25.163682Z"},"trusted":true},"outputs":[],"source":["# Initialize Wandb\n","wandb.init(project=\"GINCO-hyperparameter-search\", name=\"training_on_5_labels\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-08-16T12:50:36.049737Z","iopub.status.busy":"2022-08-16T12:50:36.047265Z","iopub.status.idle":"2022-08-16T12:50:36.060989Z","shell.execute_reply":"2022-08-16T12:50:36.059857Z","shell.execute_reply.started":"2022-08-16T12:50:36.049680Z"},"trusted":true},"outputs":[],"source":["# Calculate how many steps will each epoch have\n","# Num steps in epoch = training samples / batch size\n","steps_per_epoch = int(410/8)\n","steps_per_epoch"]},{"cell_type":"markdown","metadata":{},"source":["I evaluated per every 10th epoch - per 510 steps. I first trained the model while evaluating it to find the optimal number of epochs."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-08-16T12:50:42.484767Z","iopub.status.busy":"2022-08-16T12:50:42.484241Z","iopub.status.idle":"2022-08-16T13:06:53.449722Z","shell.execute_reply":"2022-08-16T13:06:53.448645Z","shell.execute_reply.started":"2022-08-16T12:50:42.484728Z"},"trusted":true},"outputs":[],"source":["# Create a TransformerModel and evaluate during training\n","epoch = 30\n","\n","roberta_base_model = ClassificationModel(\n","        \"xlmroberta\", \"xlm-roberta-base\",\n","        num_labels=len(LABELS),\n","        use_cuda=True,\n","        args= {\n","            \"overwrite_output_dir\": True,\n","            \"num_train_epochs\": epoch,\n","            \"train_batch_size\":8,\n","            \"learning_rate\": 1e-5,\n","            # Use these parameters if you want to evaluate during training\n","            \"evaluate_during_training\": True,\n","            \"evaluate_during_training_steps\": steps_per_epoch*10,\n","            \"evaluate_during_training_verbose\": True,\n","            \"use_cached_eval_features\": True,\n","            'reprocess_input_data': True,\n","            \"labels_list\": LABELS,\n","            # The following parameters (no_cache, no_save) are commented out if I want to save the model\n","            \"no_cache\": True,\n","            # Disable no_save: True if you want to save the model\n","            \"no_save\": True,\n","            \"max_seq_length\": 512,\n","            \"save_steps\": -1,\n","            # Only the trained model will be saved - to prevent filling all of the space\n","            \"save_model_every_epoch\":False,\n","            \"wandb_project\": 'GINCO-hyperparameter-search',\n","            \"silent\": True,\n","            }\n","        )\n","\n","# Train the model and evaluate during training\n","roberta_base_model.train_model(train_df, eval_df = dev_df)"]},{"cell_type":"markdown","metadata":{},"source":["Evaluation during training showed that the number of epochs before the eval_loss starts rising is somewhere between epochs 5 and 13. We then trained the model for epochs 5, 10, 13 and 15 to find the optimum number."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-08-16T13:13:54.682415Z","iopub.status.busy":"2022-08-16T13:13:54.681844Z","iopub.status.idle":"2022-08-16T13:13:54.699961Z","shell.execute_reply":"2022-08-16T13:13:54.696723Z","shell.execute_reply.started":"2022-08-16T13:13:54.682379Z"},"trusted":true},"outputs":[],"source":["def testing(test_df, test_name, epoch):\n","    \"\"\"\n","    This function takes the test dataset and applies the trained model on it to infer predictions.\n","    It also prints and saves a confusion matrix, calculates the F1 scores and saves the results in a list of results.\n","\n","    Args:\n","    - test_df (pandas DataFrame)\n","    - test_name\n","    - epoch: num_train_epochs\n","    \"\"\"\n","    # Get the true labels\n","    y_true = test_df.labels\n","\n","    model = roberta_base_model\n","    \n","    # Calculate the model's predictions on test\n","    def make_prediction(input_string):\n","        return model.predict([input_string])[0][0]\n","\n","    y_pred = test_df.text.apply(make_prediction)\n","\n","    # Calculate the scores\n","    macro = f1_score(y_true, y_pred, labels=LABELS, average=\"macro\")\n","    micro = f1_score(y_true, y_pred, labels=LABELS,  average=\"micro\")\n","    print(f\"Macro f1: {macro:0.3}, Micro f1: {micro:0.3}\")\n","\n","    # Plot the confusion matrix:\n","    cm = confusion_matrix(y_true, y_pred, labels=LABELS)\n","    plt.figure(figsize=(9, 9))\n","    plt.imshow(cm, cmap=\"Oranges\")\n","    for (i, j), z in np.ndenumerate(cm):\n","        plt.text(j, i, '{:d}'.format(z), ha='center', va='center')\n","    classNames = LABELS\n","    plt.ylabel('True label')\n","    plt.xlabel('Predicted label')\n","    tick_marks = np.arange(len(classNames))\n","    plt.xticks(tick_marks, classNames, rotation=90)\n","    plt.yticks(tick_marks, classNames)\n","    plt.title(f\"{test_name}\")\n","\n","    plt.tight_layout()\n","    fig1 = plt.gcf()\n","    plt.show()\n","    plt.draw()\n","    fig1.savefig(f\"Confusion-matrix-{test_name}.png\",dpi=100)\n","\n","    # Save the results:\n","    rezdict = {\n","        \"experiment\": test_name,\n","        \"num_train_epochs\": epoch,\n","        \"train_batch_size\":8,\n","        \"learning_rate\": 1e-5,\n","        \"microF1\": micro,\n","        \"macroF1\": macro,\n","        \"y_true\": y_true.to_dict(),\n","        \"y_pred\": y_pred.to_dict(),\n","        }\n","    previous_results.append(rezdict)\n","\n","    #Save intermediate results (just in case)\n","    backup = []\n","    backup.append(rezdict)\n","    with open(f\"backup-results-{test_name}.json\", \"w\") as backup_file:\n","        json.dump(backup,backup_file, indent= \"\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-08-16T13:14:33.779822Z","iopub.status.busy":"2022-08-16T13:14:33.779243Z","iopub.status.idle":"2022-08-16T13:50:08.742946Z","shell.execute_reply":"2022-08-16T13:50:08.742071Z","shell.execute_reply.started":"2022-08-16T13:14:33.779783Z"},"trusted":true},"outputs":[],"source":["# Train the model for various epochs to find the optimum number\n","epochs = [5, 10, 13, 15]\n","\n","for epoch in epochs:\n","    roberta_base_model = ClassificationModel(\n","                \"xlmroberta\", \"xlm-roberta-base\",\n","                num_labels=len(LABELS),\n","                use_cuda=True,\n","                args= {\n","                    \"overwrite_output_dir\": True,\n","                    \"num_train_epochs\": epoch,\n","                    \"train_batch_size\":8,\n","                    \"learning_rate\": 1e-5,\n","                    \"labels_list\": LABELS,\n","                    # The following parameters (no_cache, no_save) are commented out if I want to save the model\n","                    \"no_cache\": True,\n","                    # Disable no_save: True if you want to save the model\n","                    \"no_save\": True,\n","                    \"max_seq_length\": 512,\n","                    \"save_steps\": -1,\n","                    # Only the trained model will be saved - to prevent filling all of the space\n","                    \"save_model_every_epoch\":False,\n","                    \"wandb_project\": 'GINCO-hyperparameter-search',\n","                    \"silent\": True,\n","                    }\n","                )\n","\n","    # Train the model\n","    roberta_base_model.train_model(train_df)\n","    \n","    # Test the model on dev_df\n","    testing(dev_df, f\"Dev-epoch-search:{epoch}\", epoch)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-08-16T13:56:51.002981Z","iopub.status.busy":"2022-08-16T13:56:51.002202Z","iopub.status.idle":"2022-08-16T13:56:51.038521Z","shell.execute_reply":"2022-08-16T13:56:51.037345Z","shell.execute_reply.started":"2022-08-16T13:56:51.002933Z"},"trusted":true},"outputs":[],"source":["# Compare the results by creating a dataframe from the previous_results dictionary:\n","results_df = pd.DataFrame(previous_results)\n","\n","results_df"]},{"cell_type":"markdown","metadata":{},"source":["Optimum number of epochs is 13."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-08-16T13:58:14.803526Z","iopub.status.busy":"2022-08-16T13:58:14.802750Z","iopub.status.idle":"2022-08-16T14:04:28.825219Z","shell.execute_reply":"2022-08-16T14:04:28.824339Z","shell.execute_reply.started":"2022-08-16T13:58:14.803485Z"},"trusted":true},"outputs":[],"source":["# Train the model and save it\n","# Create a TransformerModel\n","roberta_base_model = ClassificationModel(\n","        \"xlmroberta\", \"xlm-roberta-base\",\n","        num_labels=len(LABELS),\n","        use_cuda=True,\n","        args= {\n","            \"overwrite_output_dir\": True,\n","            \"num_train_epochs\": 13,\n","            \"train_batch_size\":8,\n","            \"learning_rate\": 1e-5,\n","            \"labels_list\": LABELS,\n","            # The following parameters are commented out because I want to save the model\n","            #\"no_cache\": True,\n","            # Disable no_save: True if you want to save the model\n","            #\"no_save\": True,\n","            \"max_seq_length\": 512,\n","            \"save_steps\": -1,\n","            # Only the trained model will be saved - to prevent filling all of the space\n","            \"save_model_every_epoch\":False,\n","            \"wandb_project\": 'GINCO-hyperparameter-search',\n","            \"silent\": True,\n","            }\n","        )\n","\n","# Train the model\n","roberta_base_model.train_model(train_df)\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-08-16T14:08:13.091736Z","iopub.status.busy":"2022-08-16T14:08:13.091404Z","iopub.status.idle":"2022-08-16T14:08:34.270874Z","shell.execute_reply":"2022-08-16T14:08:34.269873Z","shell.execute_reply.started":"2022-08-16T14:08:13.091695Z"},"trusted":true},"outputs":[],"source":["# Save the trained model to Wandb\n","run = wandb.init(project=\"GINCO-hyperparameter-search\", entity=\"tajak\", name=\"saving-trained-model\")\n","trained_model_artifact = wandb.Artifact(\"GINCO-5-labels-classifier\", type=\"model\", description=\"a model trained on the (Slovene) GINCO dataset with only the most frequent labels (5): 'Information/Explanation', 'Promotion', 'News', 'Forum', 'Opinion/Argumentation'. The model was trained as a part of the experiments for the Exploring the Impact of Lexical and Grammatical Features on Automatic Genre Identification article, mainly to see how its performance differs from the FastText. The model was trained on keep paragraphs and all instances that are not a part of the 5 labels (created from the primary_level_3 downcasted label set) and all instances marked with hard were discarded.\")\n","trained_model_artifact.add_dir(\"outputs\")\n","run.log_artifact(trained_model_artifact)"]},{"cell_type":"markdown","metadata":{},"source":["Import all necessary libraries and install everything you need for training:"]},{"cell_type":"markdown","metadata":{},"source":["## Testing"]},{"cell_type":"code","execution_count":21,"metadata":{"execution":{"iopub.execute_input":"2022-08-18T06:53:42.971478Z","iopub.status.busy":"2022-08-18T06:53:42.971139Z","iopub.status.idle":"2022-08-18T06:53:42.978325Z","shell.execute_reply":"2022-08-18T06:53:42.977118Z","shell.execute_reply.started":"2022-08-18T06:53:42.971430Z"},"trusted":true},"outputs":[],"source":["# Create a file to save results into (you can find it under Data: Output). Be careful, run this step only once to not overwrite the results file.\n","results = []\n","\n","with open(\"GINCO-5-categories-experiments.json\", \"w\") as results_file:\n","    json.dump(results,results_file, indent= \"\")"]},{"cell_type":"code","execution_count":22,"metadata":{"execution":{"iopub.execute_input":"2022-08-18T06:53:51.321218Z","iopub.status.busy":"2022-08-18T06:53:51.320880Z","iopub.status.idle":"2022-08-18T06:53:51.330776Z","shell.execute_reply":"2022-08-18T06:53:51.329193Z","shell.execute_reply.started":"2022-08-18T06:53:51.321170Z"},"trusted":true},"outputs":[],"source":["# Open the main results file:\n","\n","previous_results_file = open(\"GINCO-5-categories-experiments.json\")\n","previous_results = json.load(previous_results_file)\n","len(previous_results)"]},{"cell_type":"code","execution_count":23,"metadata":{"execution":{"iopub.execute_input":"2022-08-18T06:53:58.093455Z","iopub.status.busy":"2022-08-18T06:53:58.092790Z","iopub.status.idle":"2022-08-18T06:53:58.099392Z","shell.execute_reply":"2022-08-18T06:53:58.098151Z","shell.execute_reply.started":"2022-08-18T06:53:58.093419Z"},"trusted":true},"outputs":[],"source":["import os\n","os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""]},{"cell_type":"code","execution_count":24,"metadata":{"execution":{"iopub.execute_input":"2022-08-18T06:54:01.473507Z","iopub.status.busy":"2022-08-18T06:54:01.473183Z","iopub.status.idle":"2022-08-18T06:54:01.482679Z","shell.execute_reply":"2022-08-18T06:54:01.481562Z","shell.execute_reply.started":"2022-08-18T06:54:01.473475Z"},"trusted":true},"outputs":[],"source":["# Create a list of labels\n","LABELS = train_df.labels.unique().tolist()\n","LABELS"]},{"cell_type":"code","execution_count":25,"metadata":{"execution":{"iopub.execute_input":"2022-08-18T06:54:10.862673Z","iopub.status.busy":"2022-08-18T06:54:10.861816Z","iopub.status.idle":"2022-08-18T06:54:18.759496Z","shell.execute_reply":"2022-08-18T06:54:18.758309Z","shell.execute_reply.started":"2022-08-18T06:54:10.862639Z"},"trusted":true},"outputs":[],"source":["# Initialize Wandb\n","run = wandb.init(project=\"GINCO-hyperparameter-search\", entity=\"tajak\", name=\"testing-trained-model-5-labels\")"]},{"cell_type":"code","execution_count":26,"metadata":{"execution":{"iopub.execute_input":"2022-08-18T06:55:26.363555Z","iopub.status.busy":"2022-08-18T06:55:26.363233Z","iopub.status.idle":"2022-08-18T06:55:59.303783Z","shell.execute_reply":"2022-08-18T06:55:59.302802Z","shell.execute_reply.started":"2022-08-18T06:55:26.363521Z"},"trusted":true},"outputs":[],"source":["# Load the saved model\n","artifact = run.use_artifact('tajak/GINCO-hyperparameter-search/GINCO-5-labels-classifier:v0', type='model')\n","artifact_dir = artifact.download()\n","\n","# Loading a local save\n","model = ClassificationModel(\n","    \"xlmroberta\", \"artifacts/GINCO-5-labels-classifier:v0\")"]},{"cell_type":"code","execution_count":27,"metadata":{"execution":{"iopub.execute_input":"2022-08-18T06:58:14.477507Z","iopub.status.busy":"2022-08-18T06:58:14.476945Z","iopub.status.idle":"2022-08-18T06:58:14.499146Z","shell.execute_reply":"2022-08-18T06:58:14.497779Z","shell.execute_reply.started":"2022-08-18T06:58:14.477473Z"},"trusted":true},"outputs":[],"source":["def testing(test_df, test_name):\n","    \"\"\"\n","    This function takes the test dataset and applies the trained model on it to infer predictions.\n","    It also prints and saves a confusion matrix, calculates the F1 scores and saves the results in a list of results.\n","\n","    Args:\n","    - test_df (pandas DataFrame)\n","    - test_name\n","    \"\"\"\n","    # Get the true labels\n","    y_true = test_df.labels\n","    \n","    # Calculate the model's predictions on test\n","    def make_prediction(input_string):\n","        return model.predict([input_string])[0][0]\n","\n","    y_pred = test_df.text.apply(make_prediction)\n","    test_df[\"y_pred_GINCO_5_labels\"] = y_pred\n","\n","    # Calculate the scores\n","    macro = f1_score(y_true, y_pred, labels=LABELS, average=\"macro\")\n","    micro = f1_score(y_true, y_pred, labels=LABELS,  average=\"micro\")\n","    print(f\"Macro f1: {macro:0.3}, Micro f1: {micro:0.3}\")\n","\n","    # Plot the confusion matrix:\n","    cm = confusion_matrix(y_true, y_pred, labels=LABELS)\n","    plt.figure(figsize=(9, 9))\n","    plt.imshow(cm, cmap=\"Oranges\")\n","    for (i, j), z in np.ndenumerate(cm):\n","        plt.text(j, i, '{:d}'.format(z), ha='center', va='center')\n","    classNames = LABELS\n","    plt.ylabel('True label')\n","    plt.xlabel('Predicted label')\n","    tick_marks = np.arange(len(classNames))\n","    plt.xticks(tick_marks, classNames, rotation=90)\n","    plt.yticks(tick_marks, classNames)\n","    plt.title(f\"{test_name}\")\n","\n","    plt.tight_layout()\n","    fig1 = plt.gcf()\n","    plt.show()\n","    plt.draw()\n","    fig1.savefig(f\"Confusion-matrix-{test_name}.png\",dpi=100)\n","\n","    # Save the results:\n","    rezdict = {\n","        \"experiment\": test_name,\n","        \"num_train_epochs\": 13,\n","        \"train_batch_size\":8,\n","        \"learning_rate\": 1e-5,\n","        \"microF1\": micro,\n","        \"macroF1\": macro,\n","        \"y_true\": y_true.to_dict(),\n","        \"y_pred\": y_pred.to_dict(),\n","        }\n","    previous_results.append(rezdict)\n","\n","    #Save intermediate results (just in case)\n","    backup = []\n","    backup.append(rezdict)\n","    with open(f\"backup-results-{test_name}.json\", \"w\") as backup_file:\n","        json.dump(backup,backup_file, indent= \"\")\n","\n","    # Save the new dataframe which contains the y_pred values as well\n","    test_df.to_csv(f\"{test_name}-sheet-with-predictions.csv\", sep=\"\\t\")"]},{"cell_type":"code","execution_count":28,"metadata":{"execution":{"iopub.execute_input":"2022-08-18T06:58:28.835868Z","iopub.status.busy":"2022-08-18T06:58:28.835476Z","iopub.status.idle":"2022-08-18T07:02:07.470873Z","shell.execute_reply":"2022-08-18T07:02:07.469534Z","shell.execute_reply.started":"2022-08-18T06:58:28.835835Z"},"trusted":true},"outputs":[],"source":["testing(dev_df, \"testing-GINCO-5-labels-on-dev\")\n","\n","print(\"\\nTesting finished.\")"]},{"cell_type":"code","execution_count":29,"metadata":{"execution":{"iopub.execute_input":"2022-08-18T07:03:33.916725Z","iopub.status.busy":"2022-08-18T07:03:33.916423Z","iopub.status.idle":"2022-08-18T07:07:16.946279Z","shell.execute_reply":"2022-08-18T07:07:16.945013Z","shell.execute_reply.started":"2022-08-18T07:03:33.916692Z"},"trusted":true},"outputs":[],"source":["testing(test_df, \"testing-GINCO-5-labels-on-test\")\n","print(\"\\nTesting finished.\")"]},{"cell_type":"code","execution_count":30,"metadata":{"execution":{"iopub.execute_input":"2022-08-18T07:11:27.476229Z","iopub.status.busy":"2022-08-18T07:11:27.475814Z","iopub.status.idle":"2022-08-18T07:11:27.510317Z","shell.execute_reply":"2022-08-18T07:11:27.509106Z","shell.execute_reply.started":"2022-08-18T07:11:27.476196Z"},"trusted":true},"outputs":[],"source":["# Compare the results by creating a dataframe from the previous_results dictionary:\n","results_df = pd.DataFrame(previous_results)\n","\n","results_df"]},{"cell_type":"code","execution_count":32,"metadata":{"execution":{"iopub.execute_input":"2022-08-18T07:13:09.799234Z","iopub.status.busy":"2022-08-18T07:13:09.798893Z","iopub.status.idle":"2022-08-18T07:13:09.817313Z","shell.execute_reply":"2022-08-18T07:13:09.815442Z","shell.execute_reply.started":"2022-08-18T07:13:09.799173Z"},"trusted":true},"outputs":[],"source":["# Save the file with updated results.\n","with open(\"GINCO-5-categories-experiments.json\", \"w\") as results_file:\n","    json.dump(previous_results,results_file, indent= \"\")"]}],"metadata":{"kernelspec":{"display_name":"Python 3.10.2 64-bit","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.2"},"vscode":{"interpreter":{"hash":"4054637ba3b142bc5aa565ef637e29d85952330aa10ad5bd25955ba00ae91bfa"}}},"nbformat":4,"nbformat_minor":4}
